{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35ba431-26cb-4a4d-ae13-b2066a99234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 12:53:36.661793: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14893737858841644049,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23284809728\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 7877654825682214480\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 12:53:37.119757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 22206 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#TensorFlowがGPUを認識しているか確認\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be3a99-abc9-43f2-b020-d8a785014616",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa12d71-7f92-4f0b-a1df-30194a335ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed, Conv2D, MaxPooling2D, Input, GRU, Dense, Activation, Dropout, Reshape, Permute, LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import metrics\n",
    "import utils\n",
    "from IPython import embed\n",
    "import keras.backend as K\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "\n",
    "plot.switch_backend('agg')\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "def load_data(_feat_folder, _mono, _fold=None):\n",
    "    \n",
    "    # Load name\n",
    "    feat_file_fold = os.path.join(_feat_folder, 'mbe123_mon_snr_0-28_step2_fold{}.npz'.format(_fold))\n",
    "        \n",
    "    dmp = np.load(feat_file_fold)\n",
    "    _X_train, _Y_train, _X_test, _Y_test = dmp['arr_0'],  dmp['arr_1'],  dmp['arr_2'],  dmp['arr_3']\n",
    "    return _X_train, _Y_train, _X_test, _Y_test\n",
    "\n",
    "mel_filt = 40\n",
    "\n",
    "def get_model(data_in, data_out, _cnn_nb_filt, _cnn_pool_size, _rnn_nb, _fc_nb):\n",
    "    \n",
    "    # input_shape (ch, time, mel)\n",
    "    spec_start = Input(shape=(data_in.shape[-3], data_in.shape[-2], data_in.shape[-1])) #default\n",
    "\n",
    "    spec_x = spec_start\n",
    "    for _i, _cnt in enumerate(_cnn_pool_size):\n",
    "        spec_x = Conv2D(filters=_cnn_nb_filt, kernel_size=(3, 3), padding='same', strides=(1, 2), data_format=\"channels_last\")(spec_x)\n",
    "        spec_x = BatchNormalization(axis=3)(spec_x)\n",
    "        spec_x = Activation('relu')(spec_x)\n",
    "        spec_x = Dropout(dropout_rate)(spec_x)\n",
    "    spec_x = Permute((1, 3, 2))(spec_x)\n",
    "    spec_x = Reshape((data_in.shape[-3], -1))(spec_x)\n",
    "\n",
    "    for _r in _rnn_nb:\n",
    "        spec_x = Bidirectional(\n",
    "            GRU(_r, activation='tanh', dropout=dropout_rate, return_sequences=True),\n",
    "            merge_mode='mul')(spec_x)\n",
    " \n",
    "    for _f in _fc_nb:\n",
    "        spec_x = TimeDistributed(Dense(_f))(spec_x)\n",
    "        spec_x = Dropout(dropout_rate)(spec_x)\n",
    "\n",
    "    spec_x = TimeDistributed(Dense(data_out.shape[-1]))(spec_x)\n",
    "    out = Activation('sigmoid', name='strong_out')(spec_x)\n",
    "\n",
    "    _model = Model(inputs=spec_start, outputs=out)\n",
    "    _model.compile(optimizer=\"Adam\", loss='binary_crossentropy')\n",
    "    _model.summary()\n",
    "    \n",
    "    return _model\n",
    "\n",
    "\n",
    "def plot_functions(_nb_epoch, _tr_loss, _val_loss, _f1, _er, extension=''):\n",
    "    plot.figure()\n",
    "\n",
    "    plot.subplot(211)\n",
    "    plot.plot(range(_nb_epoch), _tr_loss, label='train loss')\n",
    "    plot.plot(range(_nb_epoch), _val_loss, label='val loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "\n",
    "    plot.subplot(212)\n",
    "    plot.plot(range(_nb_epoch), _f1, label='f')\n",
    "    plot.plot(range(_nb_epoch), _er, label='er')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "\n",
    "    plot.savefig(__models_dir + __fig_name + extension)\n",
    "    plot.close()\n",
    "    print('figure name : {}'.format(__fig_name))\n",
    "\n",
    "\n",
    "def preprocess_data(_X, _Y, _X_test, _Y_test, _seq_len, _nb_ch):\n",
    "    # split into sequences\n",
    "    _X = utils.split_in_seqs(_X, _seq_len)\n",
    "    _Y = utils.split_in_seqs(_Y, _seq_len)\n",
    "\n",
    "    _X_test = utils.split_in_seqs(_X_test, _seq_len)\n",
    "    _Y_test = utils.split_in_seqs(_Y_test, _seq_len)\n",
    "\n",
    "    _X = utils.split_multi_channels(_X, _nb_ch)\n",
    "    _X_test = utils.split_multi_channels(_X_test, _nb_ch)\n",
    "    return _X, _Y, _X_test, _Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b31f4dd-a90b-479a-b47e-4b41c8dd93d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UNIQUE ID: mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "TRAINING PARAMETERS: nb_ch: 1, seq_len: 256, batch_size: 480, nb_epoch: 150, frames_1_sec: 93\n",
      "MODEL PARAMETERS:\n",
      " cnn_nb_filt: 128, cnn_pool_size: [2, 2, 2, 2], rnn_nb: [32, 32], fc_nb: [32], dropout_rate: 0.5\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "# MAIN SCRIPT STARTS HERE\n",
    "#######################################################################################\n",
    "\n",
    "is_mono = True  # True: mono-channel input, False: binaural input\n",
    "\n",
    "feat_folder = 'feat/'\n",
    "\n",
    "\n",
    "nb_ch = 1 if is_mono else 2\n",
    "batch_size = 480 #560    # 576でOOM # Decrease this if you want to run on smaller GPU's\n",
    "seq_len = 256       # Frame sequence length. Input to the CRNN.\n",
    "nb_epoch = 150      # Training epochs\n",
    "patience = int(0.25 * nb_epoch)  # Patience for early stopping\n",
    "\n",
    "STEP = 10 #generatorで何倍に増量するか\n",
    "\n",
    "\n",
    "# Number of frames in 1 second, required to calculate F and ER for 1 sec segments.\n",
    "# Make sure the nfft and sr are the same as in feature.py\n",
    "sr = 48000\n",
    "nfft = 1024\n",
    "frames_1_sec = int(sr/(nfft/2.0))\n",
    "\n",
    "# Folder for saving model and training curves\n",
    "__models_dir = 'models/'\n",
    "utils.create_folder(__models_dir)\n",
    "\n",
    "# CRNN model definition\n",
    "cnn_nb_filt = 128            # CNN filter size\n",
    "cnn_pool_size = [2, 2, 2, 2]   # Maxpooling across frequency. Length of cnn_pool_size =  number of CNN layers\n",
    "rnn_nb = [32, 32]           # Number of RNN nodes.  Length of rnn_nb =  number of RNN layers\n",
    "fc_nb = [32]                # Number of FC nodes.  Length of fc_nb =  number of FC layers\n",
    "dropout_rate = 0.5          # Dropout after each layer\n",
    "\n",
    "__fig_name = f'mbf{mel_filt}_cnn-f{cnn_nb_filt}-s1x2-{cnn_pool_size}_bigru{rnn_nb}_fc{fc_nb}_spec{STEP}_e{nb_epoch}p{patience}_batch{batch_size}_{time.strftime(\"%Y_%m_%d_%H_%M_%S\")}'\n",
    "\n",
    "print('\\n\\nUNIQUE ID: {}'.format(__fig_name))\n",
    "print('TRAINING PARAMETERS: nb_ch: {}, seq_len: {}, batch_size: {}, nb_epoch: {}, frames_1_sec: {}'.format(nb_ch, seq_len, batch_size, nb_epoch, frames_1_sec))\n",
    "print('MODEL PARAMETERS:\\n cnn_nb_filt: {}, cnn_pool_size: {}, rnn_nb: {}, fc_nb: {}, dropout_rate: {}'.format(cnn_nb_filt, cnn_pool_size, rnn_nb, fc_nb, dropout_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17022d1d-c26f-4919-8a69-ad4d7f9844f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load.data_X_test: (506265, 40)\n",
      "(8490, 256, 7)\n",
      "(8490, 1, 256, 40)\n",
      "(8490, 256, 7)\n",
      "(1977, 1, 256, 40)\n",
      "(1977, 256, 7)\n"
     ]
    }
   ],
   "source": [
    "X, Y, X_test, Y_test = load_data(feat_folder, is_mono, 1)\n",
    "print(\"load.data_X_test:\",X_test.shape)\n",
    "X, Y, X_test, Y_test = preprocess_data(X, Y, X_test, Y_test, seq_len, nb_ch)\n",
    "\n",
    "print(Y.shape)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8c54b",
   "metadata": {},
   "source": [
    "## SpecAugment generator\n",
    "* The aim is to improve generalization performance by randomly masking and augmenting the frequency and time domains.\n",
    "* Cited papers: https://arxiv.org/abs/1904.08779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55ef4b-1e62-41d8-89f7-69eee47e2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# class data generator\n",
    "class SpecaugmentGenerator():\n",
    "    def __init__(self, x_train, y_train, batch_size=16, alpha=0.2, shuffle=True):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_num = len(x_train)\n",
    "\n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            indexes = self.__get_exploration_order()\n",
    "            itr_num = int(len(indexes) // (self.batch_size * 2))\n",
    "\n",
    "            for i in range(itr_num):\n",
    "                batch_ids = indexes[i * self.batch_size * 2:(i + 1) * self.batch_size * 2]\n",
    "                x, y = self.__data_generation(batch_ids)\n",
    "\n",
    "                yield x, y\n",
    "\n",
    "    def __get_exploration_order(self):\n",
    "        indexes = np.arange(self.sample_num)\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indexes)\n",
    "\n",
    "        return indexes\n",
    "\n",
    "    def __data_generation(self, batch_ids):\n",
    "        \n",
    "        x1 = self.x_train[batch_ids[:self.batch_size]]\n",
    "        y = self.y_train[batch_ids[:self.batch_size]]\n",
    "\n",
    "        for j, _ in enumerate(x1): # shape(batch, time, freq, ch) = x1.shape: (64, 256, 40, 1)\n",
    "            # 時間軸のマスク\n",
    "            k = random.randint(0, 50) # max time mask1 width\n",
    "            l = random.randint(10, 200) # time mask1 start\n",
    "            x1[j, l:l+k, :, :] = 0\n",
    "                \n",
    "            # 周波数軸のマスク\n",
    "            m = random.randint(1, 8) # max freq mask width\n",
    "            n = random.randint(5, 31)  # freq mask start\n",
    "            x1[j, :, n:n+m, :] = 0\n",
    "\n",
    "        x = x1\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606b624-8062-4d72-8de5-b97705c0a6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------\n",
      "FOLD: 1\n",
      "----------------------------------------------\n",
      "\n",
      "load.data_X_test: (506265, 40)\n",
      "(8490, 256, 40, 1)\n",
      "(1977, 256, 40, 1)\n",
      "(8490, 256, 7)\n",
      "(1977, 256, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 12:53:49.958836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22206 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 40, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 20, 128)      1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 20, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 20, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 20, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 10, 128)      147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256, 10, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 5, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256, 5, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256, 5, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256, 5, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 3, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256, 3, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256, 3, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 3, 128)       0         \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 256, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256, 32)           80256     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256, 32)           12672     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 256, 32)           1056      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 32)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 256, 7)            231       \n",
      "_________________________________________________________________\n",
      "strong_out (Activation)      (None, 256, 7)            0         \n",
      "=================================================================\n",
      "Total params: 540,295\n",
      "Trainable params: 539,271\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "(8490, 256, 7)\n",
      "Epoch : 0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 12:53:51.218534: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-01 12:53:55.901484: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n",
      "2022-05-01 12:53:57.836860: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 60s 307ms/step - loss: 0.3600 - val_loss: 0.1948\n",
      "Train_loss: 0.35999056696891785, Val_loss : 0.19480334222316742, F1_overall : 0.9676245606781061, loss_overall: 0.0612884834663626 Best_loss: 0.0612884834663626, best_epoch: 0\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 305ms/step - loss: 0.1899 - val_loss: 0.1199\n",
      "Train_loss: 0.1898743212223053, Val_loss : 0.11988865584135056, F1_overall : 0.9838277688045631, loss_overall: 0.03156051474181463 Best_loss: 0.03156051474181463, best_epoch: 1\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 307ms/step - loss: 0.1606 - val_loss: 0.0731\n",
      "Train_loss: 0.16062304377555847, Val_loss : 0.07306194305419922, F1_overall : 0.9886101998818231, loss_overall: 0.022601400879622088 Best_loss: 0.022601400879622088, best_epoch: 2\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 307ms/step - loss: 0.1433 - val_loss: 0.0629\n",
      "Train_loss: 0.14334209263324738, Val_loss : 0.06293726712465286, F1_overall : 0.9896130346232178, loss_overall: 0.02060596188304284 Best_loss: 0.02060596188304284, best_epoch: 3\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 324ms/step - loss: 0.1318 - val_loss: 0.0571\n",
      "Train_loss: 0.13177916407585144, Val_loss : 0.05708662420511246, F1_overall : 0.9912019876990754, loss_overall: 0.017388825541619156 Best_loss: 0.017388825541619156, best_epoch: 4\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 330ms/step - loss: 0.1231 - val_loss: 0.0564\n",
      "Train_loss: 0.12311039865016937, Val_loss : 0.056444402784109116, F1_overall : 0.9920211683289232, loss_overall: 0.015841342238149536 Best_loss: 0.015841342238149536, best_epoch: 5\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 325ms/step - loss: 0.1152 - val_loss: 0.0536\n",
      "Train_loss: 0.11518418043851852, Val_loss : 0.05361242592334747, F1_overall : 0.992239851722101, loss_overall: 0.015434109789868056 Best_loss: 0.015434109789868056, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 333ms/step - loss: 0.1085 - val_loss: 0.0537\n",
      "Train_loss: 0.10850538313388824, Val_loss : 0.05366355553269386, F1_overall : 0.9924441457404125, loss_overall: 0.014904707607102134 Best_loss: 0.014904707607102134, best_epoch: 7\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 309ms/step - loss: 0.1032 - val_loss: 0.0530\n",
      "Train_loss: 0.10318154841661453, Val_loss : 0.05304081737995148, F1_overall : 0.9929739527116468, loss_overall: 0.01400879622088288 Best_loss: 0.01400879622088288, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 336ms/step - loss: 0.0994 - val_loss: 0.0529\n",
      "Train_loss: 0.09936797618865967, Val_loss : 0.05286896601319313, F1_overall : 0.9921195707507788, loss_overall: 0.015597002769180648 Best_loss: 0.01400879622088288, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 318ms/step - loss: 0.0956 - val_loss: 0.0485\n",
      "Train_loss: 0.0956425815820694, Val_loss : 0.04853104054927826, F1_overall : 0.9928593225511138, loss_overall: 0.01417168920019547 Best_loss: 0.01400879622088288, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 332ms/step - loss: 0.0925 - val_loss: 0.0505\n",
      "Train_loss: 0.09253046661615372, Val_loss : 0.05050024390220642, F1_overall : 0.9922884408000487, loss_overall: 0.015311940055383612 Best_loss: 0.01400879622088288, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 314ms/step - loss: 0.0901 - val_loss: 0.0499\n",
      "Train_loss: 0.09010434150695801, Val_loss : 0.049915000796318054, F1_overall : 0.9921805001221795, loss_overall: 0.015434109789868056 Best_loss: 0.01400879622088288, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 315ms/step - loss: 0.0881 - val_loss: 0.0497\n",
      "Train_loss: 0.08814119547605515, Val_loss : 0.04973990470170975, F1_overall : 0.9920407124681934, loss_overall: 0.01575989574849324 Best_loss: 0.01400879622088288, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 58s 340ms/step - loss: 0.0864 - val_loss: 0.0486\n",
      "Train_loss: 0.08643042296171188, Val_loss : 0.04856176674365997, F1_overall : 0.9925895765472311, loss_overall: 0.014660368138133246 Best_loss: 0.01400879622088288, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 325ms/step - loss: 0.0849 - val_loss: 0.0471\n",
      "Train_loss: 0.08490467816591263, Val_loss : 0.04709840565919876, F1_overall : 0.9926323930475841, loss_overall: 0.014538198403648802 Best_loss: 0.01400879622088288, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 330ms/step - loss: 0.0831 - val_loss: 0.0491\n",
      "Train_loss: 0.08311431109905243, Val_loss : 0.049070823937654495, F1_overall : 0.9925482531150744, loss_overall: 0.014660368138133246 Best_loss: 0.01400879622088288, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 322ms/step - loss: 0.0819 - val_loss: 0.0449\n",
      "Train_loss: 0.08187603950500488, Val_loss : 0.04487350210547447, F1_overall : 0.9935473364952062, loss_overall: 0.012705652386382146 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 320ms/step - loss: 0.0806 - val_loss: 0.0487\n",
      "Train_loss: 0.08057595789432526, Val_loss : 0.04868142679333687, F1_overall : 0.9926727998046079, loss_overall: 0.014497475158820656 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 323ms/step - loss: 0.0799 - val_loss: 0.0461\n",
      "Train_loss: 0.0798993781208992, Val_loss : 0.046089060604572296, F1_overall : 0.9931365959960081, loss_overall: 0.01343867079328881 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 326ms/step - loss: 0.0788 - val_loss: 0.0470\n",
      "Train_loss: 0.07882580906152725, Val_loss : 0.04696405306458473, F1_overall : 0.9928303731464884, loss_overall: 0.014049519465711029 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 331ms/step - loss: 0.0778 - val_loss: 0.0469\n",
      "Train_loss: 0.07780937850475311, Val_loss : 0.04694080725312233, F1_overall : 0.9926947886779397, loss_overall: 0.014456751913992507 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 329ms/step - loss: 0.0772 - val_loss: 0.0471\n",
      "Train_loss: 0.07723642140626907, Val_loss : 0.047141123563051224, F1_overall : 0.9921362506621032, loss_overall: 0.015434109789868056 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 310ms/step - loss: 0.0765 - val_loss: 0.0449\n",
      "Train_loss: 0.07648912817239761, Val_loss : 0.04493119567632675, F1_overall : 0.9927429876060012, loss_overall: 0.01421241244502362 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 58s 339ms/step - loss: 0.0758 - val_loss: 0.0454\n",
      "Train_loss: 0.07584377378225327, Val_loss : 0.04535704478621483, F1_overall : 0.9931427408688573, loss_overall: 0.01343867079328881 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 314ms/step - loss: 0.0755 - val_loss: 0.0459\n",
      "Train_loss: 0.07547035068273544, Val_loss : 0.04585708677768707, F1_overall : 0.9933626516817329, loss_overall: 0.013153608079491773 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 320ms/step - loss: 0.0747 - val_loss: 0.0465\n",
      "Train_loss: 0.0746857076883316, Val_loss : 0.04648754373192787, F1_overall : 0.9931399491094146, loss_overall: 0.013479394038116958 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 332ms/step - loss: 0.0741 - val_loss: 0.0454\n",
      "Train_loss: 0.07414569705724716, Val_loss : 0.045449092984199524, F1_overall : 0.9930118370922721, loss_overall: 0.013723733507085844 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 309ms/step - loss: 0.0736 - val_loss: 0.0447\n",
      "Train_loss: 0.07357098162174225, Val_loss : 0.044732414186000824, F1_overall : 0.9930907979211249, loss_overall: 0.013642287017429549 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 58s 339ms/step - loss: 0.0730 - val_loss: 0.0450\n",
      "Train_loss: 0.07302765548229218, Val_loss : 0.04501606896519661, F1_overall : 0.9934233298719279, loss_overall: 0.013072161589835478 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 307ms/step - loss: 0.0726 - val_loss: 0.0448\n",
      "Train_loss: 0.07264222204685211, Val_loss : 0.044763315469026566, F1_overall : 0.9934041773543422, loss_overall: 0.013112884834663626 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 317ms/step - loss: 0.0721 - val_loss: 0.0439\n",
      "Train_loss: 0.07209848612546921, Val_loss : 0.043919723480939865, F1_overall : 0.9934017595307916, loss_overall: 0.013112884834663626 Best_loss: 0.012705652386382146, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      " 18/170 [==>...........................] - ETA: 45s - loss: 0.0717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 52s 305ms/step - loss: 0.0605 - val_loss: 0.0508\n",
      "Train_loss: 0.06047903746366501, Val_loss : 0.050758812576532364, F1_overall : 0.9925630106562888, loss_overall: 0.014741814627789541 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 305ms/step - loss: 0.0606 - val_loss: 0.0482\n",
      "Train_loss: 0.0605752095580101, Val_loss : 0.04819561913609505, F1_overall : 0.9930565453767994, loss_overall: 0.013723733507085844 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0602 - val_loss: 0.0494\n",
      "Train_loss: 0.06023136526346207, Val_loss : 0.04936346411705017, F1_overall : 0.9927925726850719, loss_overall: 0.014293858934679915 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 303ms/step - loss: 0.0603 - val_loss: 0.0525\n",
      "Train_loss: 0.06032216548919678, Val_loss : 0.052511055022478104, F1_overall : 0.9922777562705026, loss_overall: 0.015230493565727317 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0602 - val_loss: 0.0486\n",
      "Train_loss: 0.060249269008636475, Val_loss : 0.04857088252902031, F1_overall : 0.9928503045240665, loss_overall: 0.01417168920019547 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0607 - val_loss: 0.0521\n",
      "Train_loss: 0.06068011000752449, Val_loss : 0.052065543830394745, F1_overall : 0.9925452175329964, loss_overall: 0.014741814627789541 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0602 - val_loss: 0.0522\n",
      "Train_loss: 0.060167767107486725, Val_loss : 0.05217348784208298, F1_overall : 0.9925234787214537, loss_overall: 0.014863984362273985 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 303ms/step - loss: 0.0601 - val_loss: 0.0501\n",
      "Train_loss: 0.060089949518442154, Val_loss : 0.05012967810034752, F1_overall : 0.9928095655185055, loss_overall: 0.014253135689851768 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0598 - val_loss: 0.0504\n",
      "Train_loss: 0.0598348043859005, Val_loss : 0.05035883188247681, F1_overall : 0.9924450689311095, loss_overall: 0.014945430851930282 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 303ms/step - loss: 0.0595 - val_loss: 0.0462\n",
      "Train_loss: 0.059495292603969574, Val_loss : 0.04618765041232109, F1_overall : 0.9935617945478994, loss_overall: 0.01282782212086659 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0597 - val_loss: 0.0507\n",
      "Train_loss: 0.05971561744809151, Val_loss : 0.050702936947345734, F1_overall : 0.9926885399482698, loss_overall: 0.014375305424336212 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 305ms/step - loss: 0.0595 - val_loss: 0.0490\n",
      "Train_loss: 0.05947299301624298, Val_loss : 0.048960983753204346, F1_overall : 0.9931551499348108, loss_overall: 0.013520117282945105 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0594 - val_loss: 0.0513\n",
      "Train_loss: 0.059374623000621796, Val_loss : 0.051278602331876755, F1_overall : 0.9928119082041987, loss_overall: 0.01421241244502362 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0597 - val_loss: 0.0477\n",
      "Train_loss: 0.059715576469898224, Val_loss : 0.047739818692207336, F1_overall : 0.9932391153830489, loss_overall: 0.013397947548460661 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0595 - val_loss: 0.0527\n",
      "Train_loss: 0.05951271206140518, Val_loss : 0.05268193408846855, F1_overall : 0.9925047863456758, loss_overall: 0.014863984362273985 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 305ms/step - loss: 0.0593 - val_loss: 0.0526\n",
      "Train_loss: 0.05932897329330444, Val_loss : 0.052563488483428955, F1_overall : 0.9926281920742881, loss_overall: 0.014538198403648802 Best_loss: 0.011850464244991041, best_epoch: 68\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "saved model for the best_epoch: 68 with best_f1: 0.011850464244991041 f1_for_best_er: 0.9940161198404298\n",
      "best_conf_mat: [[8.77782412e-01 1.14481817e-01 7.35656592e-03 3.79204429e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.70205450e-02 9.05690707e-01 7.53889796e-02 1.89976790e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.70662923e-04 4.10571308e-02 9.10196420e-01 4.75971563e-02\n",
      "  6.78630261e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.22292580e-03 8.51761650e-02 8.78657250e-01\n",
      "  3.23997402e-02 5.43919467e-04 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.06398349e-04 7.51289990e-03 1.34014448e-01\n",
      "  8.31228070e-01 2.70381837e-02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.15340254e-03 2.27220300e-02\n",
      "  1.95155709e-01 7.76009227e-01 4.95963091e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 7.69230769e-03\n",
      "  8.46153846e-02 4.48717949e-01 4.25641026e-01 3.33333333e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "best_conf_mat_diag: [0.87778241 0.90569071 0.91019642 0.87865725 0.83122807 0.77600923\n",
      " 0.42564103 0.        ]\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "FOLD: 2\n",
      "----------------------------------------------\n",
      "\n",
      "load.data_X_test: (506265, 40)\n",
      "(8490, 256, 40, 1)\n",
      "(1977, 256, 40, 1)\n",
      "(8490, 256, 7)\n",
      "(1977, 256, 7)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 40, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 20, 128)      1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 20, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 20, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 20, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 10, 128)      147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256, 10, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 5, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256, 5, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256, 5, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256, 5, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 3, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256, 3, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256, 3, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 3, 128)       0         \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 256, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256, 32)           80256     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256, 32)           12672     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 256, 32)           1056      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 32)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 256, 7)            231       \n",
      "_________________________________________________________________\n",
      "strong_out (Activation)      (None, 256, 7)            0         \n",
      "=================================================================\n",
      "Total params: 540,295\n",
      "Trainable params: 539,271\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "(8490, 256, 7)\n",
      "170/170 [==============================] - 56s 309ms/step - loss: 0.3569 - val_loss: 0.1433\n",
      "Train_loss: 0.3568645417690277, Val_loss : 0.14331507682800293, F1_overall : 0.9545377438507209, loss_overall: 0.08548057259713701 Best_loss: 0.08548057259713701, best_epoch: 0\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "104/170 [=================>............] - ETA: 19s - loss: 0.1971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0809 - val_loss: 0.0430\n",
      "Train_loss: 0.08085690438747406, Val_loss : 0.04297524690628052, F1_overall : 0.9941739661845588, loss_overall: 0.011480214948705422 Best_loss: 0.011235955056179775, best_epoch: 12\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0798 - val_loss: 0.0426\n",
      "Train_loss: 0.07980412244796753, Val_loss : 0.04264860227704048, F1_overall : 0.9944987775061123, loss_overall: 0.010910275199478913 Best_loss: 0.010910275199478913, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0787 - val_loss: 0.0426\n",
      "Train_loss: 0.0787184089422226, Val_loss : 0.04255371913313866, F1_overall : 0.9942766360470088, loss_overall: 0.011317375020354991 Best_loss: 0.010910275199478913, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0780 - val_loss: 0.0433\n",
      "Train_loss: 0.07803650200366974, Val_loss : 0.04333094134926796, F1_overall : 0.9944998981462618, loss_overall: 0.010869565217391304 Best_loss: 0.010869565217391304, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0772 - val_loss: 0.0420\n",
      "Train_loss: 0.07716292142868042, Val_loss : 0.04198797047138214, F1_overall : 0.9943783607625875, loss_overall: 0.011113825109916951 Best_loss: 0.010869565217391304, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 305ms/step - loss: 0.0763 - val_loss: 0.0434\n",
      "Train_loss: 0.07627757638692856, Val_loss : 0.04343951866030693, F1_overall : 0.9945190407302511, loss_overall: 0.010869565217391304 Best_loss: 0.010869565217391304, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 303ms/step - loss: 0.0759 - val_loss: 0.0432\n",
      "Train_loss: 0.07587607949972153, Val_loss : 0.0431649275124073, F1_overall : 0.99431829752571, loss_overall: 0.011276665038267384 Best_loss: 0.010869565217391304, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0752 - val_loss: 0.0429\n",
      "Train_loss: 0.07524146884679794, Val_loss : 0.04292527958750725, F1_overall : 0.9944809889416124, loss_overall: 0.010910275199478913 Best_loss: 0.010869565217391304, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 303ms/step - loss: 0.0747 - val_loss: 0.0417\n",
      "Train_loss: 0.07469012588262558, Val_loss : 0.04169843718409538, F1_overall : 0.9947469153398214, loss_overall: 0.01038104543234001 Best_loss: 0.01038104543234001, best_epoch: 26\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 303ms/step - loss: 0.0740 - val_loss: 0.0407\n",
      "Train_loss: 0.07397007197141647, Val_loss : 0.04069706052541733, F1_overall : 0.9950309547083739, loss_overall: 0.009851815665201108 Best_loss: 0.009851815665201108, best_epoch: 27\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0736 - val_loss: 0.0432\n",
      "Train_loss: 0.07359564304351807, Val_loss : 0.04317602887749672, F1_overall : 0.9945019141484075, loss_overall: 0.010869565217391304 Best_loss: 0.009851815665201108, best_epoch: 27\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 305ms/step - loss: 0.0732 - val_loss: 0.0436\n",
      "Train_loss: 0.07320787012577057, Val_loss : 0.04364492744207382, F1_overall : 0.9944587051297721, loss_overall: 0.010991695163654128 Best_loss: 0.009851815665201108, best_epoch: 27\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 305ms/step - loss: 0.0726 - val_loss: 0.0440\n",
      "Train_loss: 0.0726073756814003, Val_loss : 0.04399782791733742, F1_overall : 0.9947044686137927, loss_overall: 0.010503175378602833 Best_loss: 0.009851815665201108, best_epoch: 27\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0723 - val_loss: 0.0430\n",
      "Train_loss: 0.07228516787290573, Val_loss : 0.0429505817592144, F1_overall : 0.9945226120421086, loss_overall: 0.010828855235303697 Best_loss: 0.009851815665201108, best_epoch: 27\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0719 - val_loss: 0.0425\n",
      "Train_loss: 0.07189901918172836, Val_loss : 0.04246555268764496, F1_overall : 0.9947264471728462, loss_overall: 0.010462465396515226 Best_loss: 0.009851815665201108, best_epoch: 27\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0715 - val_loss: 0.0418\n",
      "Train_loss: 0.07150836288928986, Val_loss : 0.041761141270399094, F1_overall : 0.9948899611148434, loss_overall: 0.010136785539814362 Best_loss: 0.009851815665201108, best_epoch: 27\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0715 - val_loss: 0.0433\n",
      "Train_loss: 0.07145018875598907, Val_loss : 0.04328164458274841, F1_overall : 0.9947249434815373, loss_overall: 0.010421755414427619 Best_loss: 0.009851815665201108, best_epoch: 27\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 304ms/step - loss: 0.0709 - val_loss: 0.0415\n",
      "Train_loss: 0.0709303766489029, Val_loss : 0.04146327078342438, F1_overall : 0.9950949463700567, loss_overall: 0.009688975736850675 Best_loss: 0.009688975736850675, best_epoch: 35\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 306ms/step - loss: 0.0705 - val_loss: 0.0438\n",
      "Train_loss: 0.07049013674259186, Val_loss : 0.04378784820437431, F1_overall : 0.9948690800993605, loss_overall: 0.010218205503989579 Best_loss: 0.009688975736850675, best_epoch: 35\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 306ms/step - loss: 0.0704 - val_loss: 0.0418\n",
      "Train_loss: 0.07036741077899933, Val_loss : 0.04183310270309448, F1_overall : 0.994972624208748, loss_overall: 0.009933235629376322 Best_loss: 0.009688975736850675, best_epoch: 35\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 307ms/step - loss: 0.0699 - val_loss: 0.0426\n",
      "Train_loss: 0.06985440850257874, Val_loss : 0.04257191717624664, F1_overall : 0.9951140065146579, loss_overall: 0.009688975736850675 Best_loss: 0.009688975736850675, best_epoch: 35\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 308ms/step - loss: 0.0696 - val_loss: 0.0436\n",
      "Train_loss: 0.06962496042251587, Val_loss : 0.043572358787059784, F1_overall : 0.9949308849575538, loss_overall: 0.010096075557726755 Best_loss: 0.009688975736850675, best_epoch: 35\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 324ms/step - loss: 0.0696 - val_loss: 0.0387\n",
      "Train_loss: 0.0695570781826973, Val_loss : 0.03869054839015007, F1_overall : 0.9955408954859201, loss_overall: 0.00883406611301091 Best_loss: 0.00883406611301091, best_epoch: 40\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 331ms/step - loss: 0.0691 - val_loss: 0.0420\n",
      "Train_loss: 0.06913883984088898, Val_loss : 0.04197721183300018, F1_overall : 0.9948296217888692, loss_overall: 0.010258915486077186 Best_loss: 0.00883406611301091, best_epoch: 40\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 320ms/step - loss: 0.0690 - val_loss: 0.0444\n",
      "Train_loss: 0.06904727965593338, Val_loss : 0.0443725511431694, F1_overall : 0.9946839929119904, loss_overall: 0.01058459534277805 Best_loss: 0.00883406611301091, best_epoch: 40\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 336ms/step - loss: 0.0688 - val_loss: 0.0420\n",
      "Train_loss: 0.06875733286142349, Val_loss : 0.042005863040685654, F1_overall : 0.9951320854634702, loss_overall: 0.009688975736850675 Best_loss: 0.00883406611301091, best_epoch: 40\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 309ms/step - loss: 0.0685 - val_loss: 0.0400\n",
      "Train_loss: 0.06849845498800278, Val_loss : 0.0400274284183979, F1_overall : 0.9954198473282442, loss_overall: 0.00903761602344895 Best_loss: 0.00883406611301091, best_epoch: 40\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 323ms/step - loss: 0.0683 - val_loss: 0.0419\n",
      "Train_loss: 0.06825008988380432, Val_loss : 0.04192371293902397, F1_overall : 0.9951946571102784, loss_overall: 0.009526135808500244 Best_loss: 0.00883406611301091, best_epoch: 40\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 333ms/step - loss: 0.0681 - val_loss: 0.0403\n",
      "Train_loss: 0.0681106373667717, Val_loss : 0.04026448354125023, F1_overall : 0.9955604431410882, loss_overall: 0.008793356130923302 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 318ms/step - loss: 0.0676 - val_loss: 0.0404\n",
      "Train_loss: 0.0676024854183197, Val_loss : 0.04035157337784767, F1_overall : 0.9953378529693194, loss_overall: 0.00924116593388699 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 333ms/step - loss: 0.0674 - val_loss: 0.0426\n",
      "Train_loss: 0.06743629276752472, Val_loss : 0.04257538169622421, F1_overall : 0.9952351863164324, loss_overall: 0.00940400586223742 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 311ms/step - loss: 0.0674 - val_loss: 0.0401\n",
      "Train_loss: 0.06743079423904419, Val_loss : 0.040146492421627045, F1_overall : 0.9954802719980455, loss_overall: 0.008956196059273733 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 336ms/step - loss: 0.0671 - val_loss: 0.0400\n",
      "Train_loss: 0.06708034873008728, Val_loss : 0.04001374542713165, F1_overall : 0.9954168618744015, loss_overall: 0.009119035987624166 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 326ms/step - loss: 0.0672 - val_loss: 0.0418\n",
      "Train_loss: 0.06718621402978897, Val_loss : 0.04183444008231163, F1_overall : 0.9951138075654544, loss_overall: 0.009729685718938284 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 310ms/step - loss: 0.0667 - val_loss: 0.0407\n",
      "Train_loss: 0.06673121452331543, Val_loss : 0.040659256279468536, F1_overall : 0.995357550089591, loss_overall: 0.00920045595179938 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 323ms/step - loss: 0.0665 - val_loss: 0.0399\n",
      "Train_loss: 0.0665006935596466, Val_loss : 0.03986763581633568, F1_overall : 0.995358306188925, loss_overall: 0.00920045595179938 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 315ms/step - loss: 0.0665 - val_loss: 0.0407\n",
      "Train_loss: 0.06646528840065002, Val_loss : 0.04073476046323776, F1_overall : 0.9954189147918151, loss_overall: 0.009078326005536557 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 319ms/step - loss: 0.0661 - val_loss: 0.0423\n",
      "Train_loss: 0.06608372926712036, Val_loss : 0.04225533828139305, F1_overall : 0.9951322837532331, loss_overall: 0.009648265754763068 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 324ms/step - loss: 0.0660 - val_loss: 0.0422\n",
      "Train_loss: 0.06599173694849014, Val_loss : 0.04224766045808792, F1_overall : 0.9950925492272291, loss_overall: 0.009729685718938284 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 312ms/step - loss: 0.0658 - val_loss: 0.0419\n",
      "Train_loss: 0.0658336877822876, Val_loss : 0.04186658188700676, F1_overall : 0.9952143366255981, loss_overall: 0.009485425826412637 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 318ms/step - loss: 0.0657 - val_loss: 0.0400\n",
      "Train_loss: 0.06567111611366272, Val_loss : 0.04001399874687195, F1_overall : 0.9952969440315979, loss_overall: 0.009322585898062204 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 335ms/step - loss: 0.0657 - val_loss: 0.0416\n",
      "Train_loss: 0.06566019356250763, Val_loss : 0.04157443344593048, F1_overall : 0.9950504124656278, loss_overall: 0.009811105683113499 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 312ms/step - loss: 0.0652 - val_loss: 0.0417\n",
      "Train_loss: 0.06524769961833954, Val_loss : 0.041733432561159134, F1_overall : 0.9951136086000488, loss_overall: 0.009688975736850675 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 320ms/step - loss: 0.0653 - val_loss: 0.0398\n",
      "Train_loss: 0.06533930450677872, Val_loss : 0.0397653765976429, F1_overall : 0.9952957947255879, loss_overall: 0.009322585898062204 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 336ms/step - loss: 0.0658 - val_loss: 0.0411\n",
      "Train_loss: 0.06579985469579697, Val_loss : 0.04110410436987877, F1_overall : 0.9950092685013545, loss_overall: 0.009892525647288715 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 311ms/step - loss: 0.0653 - val_loss: 0.0403\n",
      "Train_loss: 0.06531883776187897, Val_loss : 0.04026190936565399, F1_overall : 0.9952344100036657, loss_overall: 0.009444715844325028 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 330ms/step - loss: 0.0648 - val_loss: 0.0396\n",
      "Train_loss: 0.06480029970407486, Val_loss : 0.03957606479525566, F1_overall : 0.995416488418994, loss_overall: 0.009078326005536557 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 327ms/step - loss: 0.0648 - val_loss: 0.0413\n",
      "Train_loss: 0.06478254497051239, Val_loss : 0.04129355028271675, F1_overall : 0.995337093522836, loss_overall: 0.00924116593388699 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 335ms/step - loss: 0.0646 - val_loss: 0.0419\n",
      "Train_loss: 0.06459467858076096, Val_loss : 0.04193996638059616, F1_overall : 0.9952347981916669, loss_overall: 0.009444715844325028 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 314ms/step - loss: 0.0643 - val_loss: 0.0408\n",
      "Train_loss: 0.0643463134765625, Val_loss : 0.04083668068051338, F1_overall : 0.9952542925229646, loss_overall: 0.00940400586223742 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 334ms/step - loss: 0.0643 - val_loss: 0.0417\n",
      "Train_loss: 0.06426122039556503, Val_loss : 0.04170377552509308, F1_overall : 0.9952768729641692, loss_overall: 0.009363295880149813 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 329ms/step - loss: 0.0641 - val_loss: 0.0400\n",
      "Train_loss: 0.06405135244131088, Val_loss : 0.04004818573594093, F1_overall : 0.9954576008799624, loss_overall: 0.008996906041361342 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 314ms/step - loss: 0.0640 - val_loss: 0.0413\n",
      "Train_loss: 0.06404280662536621, Val_loss : 0.04130309820175171, F1_overall : 0.9954799038970558, loss_overall: 0.008996906041361342 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 317ms/step - loss: 0.0638 - val_loss: 0.0405\n",
      "Train_loss: 0.06384286284446716, Val_loss : 0.04046681150794029, F1_overall : 0.995356982853419, loss_overall: 0.00924116593388699 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 58s 339ms/step - loss: 0.0639 - val_loss: 0.0424\n",
      "Train_loss: 0.06394808739423752, Val_loss : 0.04239022731781006, F1_overall : 0.9951736075756031, loss_overall: 0.009566845790587851 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 310ms/step - loss: 0.0637 - val_loss: 0.0410\n",
      "Train_loss: 0.06366485357284546, Val_loss : 0.04103345051407814, F1_overall : 0.99529445315842, loss_overall: 0.009322585898062204 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 317ms/step - loss: 0.0635 - val_loss: 0.0414\n",
      "Train_loss: 0.06354706734418869, Val_loss : 0.04140631482005119, F1_overall : 0.9953141553255642, loss_overall: 0.009281875915974597 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 58s 339ms/step - loss: 0.0638 - val_loss: 0.0414\n",
      "Train_loss: 0.06379472464323044, Val_loss : 0.04139148071408272, F1_overall : 0.9953154914660473, loss_overall: 0.009281875915974597 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 311ms/step - loss: 0.0636 - val_loss: 0.0414\n",
      "Train_loss: 0.06361904740333557, Val_loss : 0.04141451045870781, F1_overall : 0.995275141542096, loss_overall: 0.00940400586223742 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 323ms/step - loss: 0.0633 - val_loss: 0.0407\n",
      "Train_loss: 0.06330811232328415, Val_loss : 0.040726225823163986, F1_overall : 0.9952157006453713, loss_overall: 0.009485425826412637 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 320ms/step - loss: 0.0633 - val_loss: 0.0397\n",
      "Train_loss: 0.06332918256521225, Val_loss : 0.03972023352980614, F1_overall : 0.9952566112253413, loss_overall: 0.009444715844325028 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 326ms/step - loss: 0.0630 - val_loss: 0.0392\n",
      "Train_loss: 0.06300071626901627, Val_loss : 0.03918711841106415, F1_overall : 0.9952762959644907, loss_overall: 0.00940400586223742 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 321ms/step - loss: 0.0629 - val_loss: 0.0435\n",
      "Train_loss: 0.06290096789598465, Val_loss : 0.043480414897203445, F1_overall : 0.9952369320957497, loss_overall: 0.009444715844325028 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 323ms/step - loss: 0.0633 - val_loss: 0.0432\n",
      "Train_loss: 0.06325149536132812, Val_loss : 0.04319519177079201, F1_overall : 0.9952971355280034, loss_overall: 0.009322585898062204 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 312ms/step - loss: 0.0629 - val_loss: 0.0434\n",
      "Train_loss: 0.06287391483783722, Val_loss : 0.04335398972034454, F1_overall : 0.9952776420778374, loss_overall: 0.009363295880149813 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 338ms/step - loss: 0.0629 - val_loss: 0.0425\n",
      "Train_loss: 0.06289203464984894, Val_loss : 0.042516812682151794, F1_overall : 0.995335573887361, loss_overall: 0.00924116593388699 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 312ms/step - loss: 0.0626 - val_loss: 0.0417\n",
      "Train_loss: 0.06261204928159714, Val_loss : 0.04173848778009415, F1_overall : 0.9953564154786148, loss_overall: 0.00924116593388699 Best_loss: 0.008793356130923302, best_epoch: 46\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "saved model for the best_epoch: 46 with best_f1: 0.008793356130923302 f1_for_best_er: 0.9955604431410882\n",
      "best_conf_mat: [[9.02977114e-01 8.60162917e-02 1.10065943e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.31337078e-02 9.20416087e-01 6.40708482e-02 2.36217767e-03\n",
      "  1.71794740e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.23435819e-04 3.76775146e-02 9.13239352e-01 4.77009493e-02\n",
      "  1.15355237e-03 5.19618185e-06 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.53635643e-03 7.82021429e-02 8.83292924e-01\n",
      "  3.63844412e-02 5.76133663e-04 8.00185643e-06 0.00000000e+00]\n",
      " [0.00000000e+00 6.73945276e-05 3.59437480e-03 1.12144494e-01\n",
      "  8.55865570e-01 2.82607719e-02 6.73945276e-05 0.00000000e+00]\n",
      " [0.00000000e+00 1.49566258e-04 8.97397547e-04 2.57253964e-02\n",
      "  2.67873168e-01 6.90846545e-01 1.43583608e-02 1.49566258e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.33333333e-02 3.46666667e-01 6.35555556e-01 4.44444444e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "best_conf_mat_diag: [0.90297711 0.92041609 0.91323935 0.88329292 0.85586557 0.69084655\n",
      " 0.63555556 0.        ]\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "FOLD: 4\n",
      "----------------------------------------------\n",
      "\n",
      "load.data_X_test: (506265, 40)\n",
      "(8490, 256, 40, 1)\n",
      "(1977, 256, 40, 1)\n",
      "(8490, 256, 7)\n",
      "(1977, 256, 7)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 40, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 20, 128)      1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 20, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 20, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 20, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 10, 128)      147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256, 10, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 5, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256, 5, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256, 5, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256, 5, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 3, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256, 3, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256, 3, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 3, 128)       0         \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 256, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256, 32)           80256     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256, 32)           12672     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 256, 32)           1056      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 32)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 256, 7)            231       \n",
      "_________________________________________________________________\n",
      "strong_out (Activation)      (None, 256, 7)            0         \n",
      "=================================================================\n",
      "Total params: 540,295\n",
      "Trainable params: 539,271\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "(8490, 256, 7)\n",
      "170/170 [==============================] - 61s 333ms/step - loss: 0.3565 - val_loss: 0.1693\n",
      "Train_loss: 0.35647544264793396, Val_loss : 0.16927695274353027, F1_overall : 0.9576538942725672, loss_overall: 0.08105784582633971 Best_loss: 0.08105784582633971, best_epoch: 0\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 318ms/step - loss: 0.1927 - val_loss: 0.1058\n",
      "Train_loss: 0.19267533719539642, Val_loss : 0.10581036657094955, F1_overall : 0.9788689793278956, loss_overall: 0.041306750726654934 Best_loss: 0.041306750726654934, best_epoch: 1\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 334ms/step - loss: 0.1626 - val_loss: 0.0648\n",
      "Train_loss: 0.1625780314207077, Val_loss : 0.06480491161346436, F1_overall : 0.9878890588186665, loss_overall: 0.023907970688172922 Best_loss: 0.023907970688172922, best_epoch: 2\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 314ms/step - loss: 0.1449 - val_loss: 0.0572\n",
      "Train_loss: 0.1449117213487625, Val_loss : 0.05718619376420975, F1_overall : 0.9917392733848429, loss_overall: 0.01625250747124084 Best_loss: 0.01625250747124084, best_epoch: 3\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 315ms/step - loss: 0.1315 - val_loss: 0.0546\n",
      "Train_loss: 0.13152126967906952, Val_loss : 0.05458303913474083, F1_overall : 0.9922111017489055, loss_overall: 0.015433741351782864 Best_loss: 0.015433741351782864, best_epoch: 4\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 319ms/step - loss: 0.1217 - val_loss: 0.0530\n",
      "Train_loss: 0.12168915569782257, Val_loss : 0.0529923178255558, F1_overall : 0.9926728649713686, loss_overall: 0.014492160314406189 Best_loss: 0.014492160314406189, best_epoch: 5\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 333ms/step - loss: 0.1139 - val_loss: 0.0502\n",
      "Train_loss: 0.11391779035329819, Val_loss : 0.05020708218216896, F1_overall : 0.9933193983359974, loss_overall: 0.013182134523273426 Best_loss: 0.013182134523273426, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 311ms/step - loss: 0.1086 - val_loss: 0.0494\n",
      "Train_loss: 0.10858164727687836, Val_loss : 0.04944116994738579, F1_overall : 0.9938655341498942, loss_overall: 0.012199615179923854 Best_loss: 0.012199615179923854, best_epoch: 7\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 322ms/step - loss: 0.1039 - val_loss: 0.0485\n",
      "Train_loss: 0.10392486304044724, Val_loss : 0.04852430149912834, F1_overall : 0.9932064938530056, loss_overall: 0.013468702665083718 Best_loss: 0.012199615179923854, best_epoch: 7\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 316ms/step - loss: 0.1003 - val_loss: 0.0483\n",
      "Train_loss: 0.10025115311145782, Val_loss : 0.04834415391087532, F1_overall : 0.9929777011211037, loss_overall: 0.013959962336758504 Best_loss: 0.012199615179923854, best_epoch: 7\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 316ms/step - loss: 0.0971 - val_loss: 0.0485\n",
      "Train_loss: 0.09714554250240326, Val_loss : 0.04846416041254997, F1_overall : 0.9934924968694188, loss_overall: 0.012936504687436033 Best_loss: 0.012199615179923854, best_epoch: 7\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 58s 339ms/step - loss: 0.0947 - val_loss: 0.0481\n",
      "Train_loss: 0.09472354501485825, Val_loss : 0.04812757298350334, F1_overall : 0.9939495867260085, loss_overall: 0.012035861956032259 Best_loss: 0.012035861956032259, best_epoch: 11\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 330ms/step - loss: 0.0925 - val_loss: 0.0485\n",
      "Train_loss: 0.09248915314674377, Val_loss : 0.0485379733145237, F1_overall : 0.9935608235583625, loss_overall: 0.012772751463544438 Best_loss: 0.012035861956032259, best_epoch: 11\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 323ms/step - loss: 0.0908 - val_loss: 0.0496\n",
      "Train_loss: 0.0907653421163559, Val_loss : 0.04961924999952316, F1_overall : 0.993806906734476, loss_overall: 0.01232243009784255 Best_loss: 0.012035861956032259, best_epoch: 11\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 330ms/step - loss: 0.0890 - val_loss: 0.0470\n",
      "Train_loss: 0.08896800130605698, Val_loss : 0.046965356916189194, F1_overall : 0.9941354986876638, loss_overall: 0.01166741720227617 Best_loss: 0.01166741720227617, best_epoch: 14\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 309ms/step - loss: 0.0875 - val_loss: 0.0476\n",
      "Train_loss: 0.0875440314412117, Val_loss : 0.04763384908437729, F1_overall : 0.9941968954415895, loss_overall: 0.011544602284357473 Best_loss: 0.011544602284357473, best_epoch: 15\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 322ms/step - loss: 0.0857 - val_loss: 0.0480\n",
      "Train_loss: 0.08569955825805664, Val_loss : 0.04801514372229576, F1_overall : 0.9935785651273003, loss_overall: 0.012731813157571539 Best_loss: 0.011544602284357473, best_epoch: 15\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 314ms/step - loss: 0.0839 - val_loss: 0.0497\n",
      "Train_loss: 0.0838548094034195, Val_loss : 0.04969708248972893, F1_overall : 0.993928205128205, loss_overall: 0.012076800262005158 Best_loss: 0.011544602284357473, best_epoch: 15\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 58s 340ms/step - loss: 0.0828 - val_loss: 0.0482\n",
      "Train_loss: 0.08284062147140503, Val_loss : 0.04824411869049072, F1_overall : 0.9939292013618277, loss_overall: 0.012035861956032259 Best_loss: 0.011544602284357473, best_epoch: 15\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 308ms/step - loss: 0.0815 - val_loss: 0.0496\n",
      "Train_loss: 0.08148752897977829, Val_loss : 0.049607716500759125, F1_overall : 0.9942611190817789, loss_overall: 0.011380849060465877 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 332ms/step - loss: 0.0808 - val_loss: 0.0487\n",
      "Train_loss: 0.0807642936706543, Val_loss : 0.04873572289943695, F1_overall : 0.9938242475225177, loss_overall: 0.012240553485896753 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 319ms/step - loss: 0.0795 - val_loss: 0.0501\n",
      "Train_loss: 0.07946757972240448, Val_loss : 0.05005102604627609, F1_overall : 0.9937039847419044, loss_overall: 0.012486183321734146 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 324ms/step - loss: 0.0786 - val_loss: 0.0485\n",
      "Train_loss: 0.07857098430395126, Val_loss : 0.04849040508270264, F1_overall : 0.9939528114302112, loss_overall: 0.01199492365005936 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 316ms/step - loss: 0.0778 - val_loss: 0.0495\n",
      "Train_loss: 0.07775494456291199, Val_loss : 0.04954502731561661, F1_overall : 0.9940149217020577, loss_overall: 0.011872108732140663 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 336ms/step - loss: 0.0769 - val_loss: 0.0483\n",
      "Train_loss: 0.07688728719949722, Val_loss : 0.048292066901922226, F1_overall : 0.9942390880947988, loss_overall: 0.011380849060465877 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 314ms/step - loss: 0.0760 - val_loss: 0.0477\n",
      "Train_loss: 0.07599516212940216, Val_loss : 0.04765813797712326, F1_overall : 0.994260883823891, loss_overall: 0.011421787366438776 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 316ms/step - loss: 0.0755 - val_loss: 0.0493\n",
      "Train_loss: 0.0755097046494484, Val_loss : 0.049310825765132904, F1_overall : 0.9938904379202885, loss_overall: 0.012076800262005158 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 58s 340ms/step - loss: 0.0745 - val_loss: 0.0500\n",
      "Train_loss: 0.0744779035449028, Val_loss : 0.04996725544333458, F1_overall : 0.9937880558459928, loss_overall: 0.01236336840381545 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 327ms/step - loss: 0.0739 - val_loss: 0.0488\n",
      "Train_loss: 0.07392705231904984, Val_loss : 0.04884633421897888, F1_overall : 0.9939729397293972, loss_overall: 0.01199492365005936 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 320ms/step - loss: 0.0734 - val_loss: 0.0508\n",
      "Train_loss: 0.0733586847782135, Val_loss : 0.05083400011062622, F1_overall : 0.9934782608695651, loss_overall: 0.012895566381463134 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 319ms/step - loss: 0.0726 - val_loss: 0.0517\n",
      "Train_loss: 0.07260762155056, Val_loss : 0.051664840430021286, F1_overall : 0.9935407140074229, loss_overall: 0.012854628075490235 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 333ms/step - loss: 0.0722 - val_loss: 0.0500\n",
      "Train_loss: 0.07217354327440262, Val_loss : 0.050035178661346436, F1_overall : 0.9938906884251096, loss_overall: 0.012158676873950955 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 328ms/step - loss: 0.0716 - val_loss: 0.0511\n",
      "Train_loss: 0.07163945585489273, Val_loss : 0.05106603726744652, F1_overall : 0.9932530812296207, loss_overall: 0.01342776435911082 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 316ms/step - loss: 0.0713 - val_loss: 0.0502\n",
      "Train_loss: 0.07133250683546066, Val_loss : 0.050150029361248016, F1_overall : 0.9935420382557353, loss_overall: 0.012854628075490235 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 324ms/step - loss: 0.0708 - val_loss: 0.0517\n",
      "Train_loss: 0.07081149518489838, Val_loss : 0.051692504435777664, F1_overall : 0.9933340170238948, loss_overall: 0.013264011135219224 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 322ms/step - loss: 0.0704 - val_loss: 0.0523\n",
      "Train_loss: 0.07039155066013336, Val_loss : 0.05230148136615753, F1_overall : 0.992652189975781, loss_overall: 0.014574036926351987 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 328ms/step - loss: 0.0699 - val_loss: 0.0523\n",
      "Train_loss: 0.06992308795452118, Val_loss : 0.05232706665992737, F1_overall : 0.9932929955901957, loss_overall: 0.013304949441192123 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 315ms/step - loss: 0.0694 - val_loss: 0.0551\n",
      "Train_loss: 0.06942477077245712, Val_loss : 0.055109862238168716, F1_overall : 0.9921001333743714, loss_overall: 0.015720309493593154 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 313ms/step - loss: 0.0691 - val_loss: 0.0552\n",
      "Train_loss: 0.06906655430793762, Val_loss : 0.055208779871463776, F1_overall : 0.9920147798419376, loss_overall: 0.01588406271748475 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 315ms/step - loss: 0.0686 - val_loss: 0.0538\n",
      "Train_loss: 0.06860431283712387, Val_loss : 0.05382702872157097, F1_overall : 0.9926758714071763, loss_overall: 0.014533098620379088 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 338ms/step - loss: 0.0684 - val_loss: 0.0531\n",
      "Train_loss: 0.0684356614947319, Val_loss : 0.05310281738638878, F1_overall : 0.9925299622393695, loss_overall: 0.014778728456216481 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 327ms/step - loss: 0.0678 - val_loss: 0.0547\n",
      "Train_loss: 0.06782859563827515, Val_loss : 0.05471062660217285, F1_overall : 0.9923883383599021, loss_overall: 0.015106234903999672 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 314ms/step - loss: 0.0678 - val_loss: 0.0559\n",
      "Train_loss: 0.06778760999441147, Val_loss : 0.055909834802150726, F1_overall : 0.992039066026509, loss_overall: 0.015843124411511852 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 335ms/step - loss: 0.0674 - val_loss: 0.0531\n",
      "Train_loss: 0.06744427233934402, Val_loss : 0.05312228575348854, F1_overall : 0.9929869171143828, loss_overall: 0.013959962336758504 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 327ms/step - loss: 0.0672 - val_loss: 0.0555\n",
      "Train_loss: 0.06719080358743668, Val_loss : 0.055482346564531326, F1_overall : 0.9924525206120021, loss_overall: 0.015024358292053874 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 56s 330ms/step - loss: 0.0667 - val_loss: 0.0580\n",
      "Train_loss: 0.06672670692205429, Val_loss : 0.05795108526945114, F1_overall : 0.9924700958164918, loss_overall: 0.014983419986080975 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 321ms/step - loss: 0.0666 - val_loss: 0.0549\n",
      "Train_loss: 0.06664162129163742, Val_loss : 0.054914187639951706, F1_overall : 0.9927824482263686, loss_overall: 0.014369345396487493 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 54s 320ms/step - loss: 0.0661 - val_loss: 0.0567\n",
      "Train_loss: 0.06611491739749908, Val_loss : 0.05672593414783478, F1_overall : 0.9926818768833405, loss_overall: 0.014574036926351987 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 57s 333ms/step - loss: 0.0660 - val_loss: 0.0595\n",
      "Train_loss: 0.066031314432621, Val_loss : 0.05949984863400459, F1_overall : 0.9918539037652611, loss_overall: 0.016170630859295043 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 308ms/step - loss: 0.0658 - val_loss: 0.0576\n",
      "Train_loss: 0.06583666801452637, Val_loss : 0.05760875716805458, F1_overall : 0.992244244737166, loss_overall: 0.015433741351782864 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 58s 340ms/step - loss: 0.0657 - val_loss: 0.0549\n",
      "Train_loss: 0.06568904221057892, Val_loss : 0.05492604896426201, F1_overall : 0.9928821972882605, loss_overall: 0.014164653866622998 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 323ms/step - loss: 0.0654 - val_loss: 0.0599\n",
      "Train_loss: 0.06544368714094162, Val_loss : 0.0598832331597805, F1_overall : 0.9918742561661262, loss_overall: 0.01621156916526794 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 325ms/step - loss: 0.0651 - val_loss: 0.0623\n",
      "Train_loss: 0.0650889053940773, Val_loss : 0.06230303272604942, F1_overall : 0.9918345574658405, loss_overall: 0.01625250747124084 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 53s 312ms/step - loss: 0.0648 - val_loss: 0.0590\n",
      "Train_loss: 0.06484062969684601, Val_loss : 0.058964986354112625, F1_overall : 0.9919776770143005, loss_overall: 0.015965939329430547 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 326ms/step - loss: 0.0648 - val_loss: 0.0631\n",
      "Train_loss: 0.06480581313371658, Val_loss : 0.06308750808238983, F1_overall : 0.99195798457246, loss_overall: 0.01592500102345765 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 52s 308ms/step - loss: 0.0648 - val_loss: 0.0570\n",
      "Train_loss: 0.06482193619012833, Val_loss : 0.05701800808310509, F1_overall : 0.9925342521946016, loss_overall: 0.014778728456216481 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 59s 345ms/step - loss: 0.0643 - val_loss: 0.0597\n",
      "Train_loss: 0.06427021324634552, Val_loss : 0.05972057208418846, F1_overall : 0.9920994849274588, loss_overall: 0.015720309493593154 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "170/170 [==============================] - 55s 325ms/step - loss: 0.0639 - val_loss: 0.0567\n",
      "Train_loss: 0.0639001727104187, Val_loss : 0.05667825788259506, F1_overall : 0.9929275742604702, loss_overall: 0.014041838948704302 Best_loss: 0.011380849060465877, best_epoch: 19\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "saved model for the best_epoch: 19 with best_f1: 0.011380849060465877 f1_for_best_er: 0.9942611190817789\n",
      "best_conf_mat: [[8.45378330e-01 1.46308677e-01 8.27761859e-03 3.53744384e-05\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.55382538e-02 8.84129974e-01 9.57469865e-02 4.43473767e-03\n",
      "  1.50047515e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.74105939e-04 3.93873453e-02 8.94771289e-01 6.32233740e-02\n",
      "  2.31032149e-03 3.35639925e-05 0.00000000e+00 0.00000000e+00]\n",
      " [1.60096058e-05 1.86511907e-03 8.01360816e-02 8.70250150e-01\n",
      "  4.72203322e-02 5.12307384e-04 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 7.10915789e-04 5.62269760e-03 1.42204701e-01\n",
      "  8.24296086e-01 2.65623990e-02 6.03201275e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.89367373e-02\n",
      "  2.47720578e-01 7.23243092e-01 1.00995932e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.66666667e-03\n",
      "  1.83333333e-02 2.56666667e-01 7.15000000e-01 8.33333333e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.22222222e-02 1.33333333e-01 4.44444444e-01 4.00000000e-01]]\n",
      "best_conf_mat_diag: [0.84537833 0.88412997 0.89477129 0.87025015 0.82429609 0.72324309\n",
      " 0.715      0.4       ]\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "FOLD: 5\n",
      "----------------------------------------------\n",
      "\n",
      "load.data_X_test: (654795, 40)\n",
      "(7910, 256, 40, 1)\n",
      "(2557, 256, 40, 1)\n",
      "(7910, 256, 7)\n",
      "(2557, 256, 7)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 40, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 20, 128)      1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 20, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 20, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 20, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 10, 128)      147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256, 10, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 5, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256, 5, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256, 5, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256, 5, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 3, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256, 3, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256, 3, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 3, 128)       0         \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 256, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256, 32)           80256     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256, 32)           12672     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 256, 32)           1056      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 32)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 256, 7)            231       \n",
      "_________________________________________________________________\n",
      "strong_out (Activation)      (None, 256, 7)            0         \n",
      "=================================================================\n",
      "Total params: 540,295\n",
      "Trainable params: 539,271\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "(7910, 256, 7)\n",
      "160/160 [==============================] - 55s 316ms/step - loss: 0.3696 - val_loss: 0.2078\n",
      "Train_loss: 0.36963263154029846, Val_loss : 0.20780742168426514, F1_overall : 0.9662189399680732, loss_overall: 0.06526674233825198 Best_loss: 0.06526674233825198, best_epoch: 0\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.1982 - val_loss: 0.1517\n",
      "Train_loss: 0.1982279121875763, Val_loss : 0.15165714919567108, F1_overall : 0.9782211245469415, loss_overall: 0.042470677260688615 Best_loss: 0.042470677260688615, best_epoch: 1\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 54s 338ms/step - loss: 0.1684 - val_loss: 0.0877\n",
      "Train_loss: 0.1683521419763565, Val_loss : 0.08770649880170822, F1_overall : 0.9913445258477458, loss_overall: 0.01712069617858494 Best_loss: 0.01712069617858494, best_epoch: 2\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 53s 331ms/step - loss: 0.1507 - val_loss: 0.0655\n",
      "Train_loss: 0.15074583888053894, Val_loss : 0.0655180886387825, F1_overall : 0.9932616894696144, loss_overall: 0.01343170639424896 Best_loss: 0.01343170639424896, best_epoch: 3\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.1364 - val_loss: 0.0604\n",
      "Train_loss: 0.13639450073242188, Val_loss : 0.06038295477628708, F1_overall : 0.9944831499637462, loss_overall: 0.011003909698574852 Best_loss: 0.011003909698574852, best_epoch: 4\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 55s 343ms/step - loss: 0.1249 - val_loss: 0.0584\n",
      "Train_loss: 0.12492235749959946, Val_loss : 0.05835920572280884, F1_overall : 0.9946566209038034, loss_overall: 0.010688611426409384 Best_loss: 0.010688611426409384, best_epoch: 5\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 321ms/step - loss: 0.1158 - val_loss: 0.0562\n",
      "Train_loss: 0.11582248657941818, Val_loss : 0.05619373545050621, F1_overall : 0.9957080190614447, loss_overall: 0.008544583175684198 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 52s 327ms/step - loss: 0.1089 - val_loss: 0.0551\n",
      "Train_loss: 0.10885392874479294, Val_loss : 0.055115219205617905, F1_overall : 0.9952020202020201, loss_overall: 0.009553537646613696 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 315ms/step - loss: 0.1041 - val_loss: 0.0539\n",
      "Train_loss: 0.10414255410432816, Val_loss : 0.05391939356923103, F1_overall : 0.9955489614243322, loss_overall: 0.00882835162063312 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 54s 340ms/step - loss: 0.0999 - val_loss: 0.0547\n",
      "Train_loss: 0.0998503640294075, Val_loss : 0.05469943583011627, F1_overall : 0.9954865385222357, loss_overall: 0.008954470929499306 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 52s 323ms/step - loss: 0.0964 - val_loss: 0.0534\n",
      "Train_loss: 0.09642554074525833, Val_loss : 0.05342153459787369, F1_overall : 0.9954721148536718, loss_overall: 0.008986000756715852 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 54s 336ms/step - loss: 0.0939 - val_loss: 0.0550\n",
      "Train_loss: 0.09388461709022522, Val_loss : 0.05495622009038925, F1_overall : 0.9954388346143526, loss_overall: 0.0090175305839324 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 315ms/step - loss: 0.0916 - val_loss: 0.0536\n",
      "Train_loss: 0.09155112504959106, Val_loss : 0.0535847507417202, F1_overall : 0.9955342349024001, loss_overall: 0.008859881447849665 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 54s 338ms/step - loss: 0.0892 - val_loss: 0.0536\n",
      "Train_loss: 0.0892268717288971, Val_loss : 0.05363750085234642, F1_overall : 0.9951983826130906, loss_overall: 0.009490477992180602 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 318ms/step - loss: 0.0873 - val_loss: 0.0531\n",
      "Train_loss: 0.08734964579343796, Val_loss : 0.05314488336443901, F1_overall : 0.9955326840202685, loss_overall: 0.00882835162063312 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 317ms/step - loss: 0.0855 - val_loss: 0.0559\n",
      "Train_loss: 0.08547074347734451, Val_loss : 0.05588899925351143, F1_overall : 0.9955655151735129, loss_overall: 0.008765291966200026 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 55s 344ms/step - loss: 0.0837 - val_loss: 0.0534\n",
      "Train_loss: 0.0837247371673584, Val_loss : 0.05337222293019295, F1_overall : 0.9952494436640834, loss_overall: 0.009395888510530963 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 0.0823 - val_loss: 0.0558\n",
      "Train_loss: 0.0823015496134758, Val_loss : 0.05579124763607979, F1_overall : 0.9948219247284666, loss_overall: 0.010310253499810821 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 319ms/step - loss: 0.0809 - val_loss: 0.0540\n",
      "Train_loss: 0.08090409636497498, Val_loss : 0.05396105721592903, F1_overall : 0.9945524308790321, loss_overall: 0.010814730735275571 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 55s 341ms/step - loss: 0.0797 - val_loss: 0.0541\n",
      "Train_loss: 0.07967233657836914, Val_loss : 0.05407733470201492, F1_overall : 0.9952160664382587, loss_overall: 0.009490477992180602 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 0.0784 - val_loss: 0.0555\n",
      "Train_loss: 0.07843739539384842, Val_loss : 0.05546017363667488, F1_overall : 0.9949475811544777, loss_overall: 0.0100264850548619 Best_loss: 0.008544583175684198, best_epoch: 6\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 55s 343ms/step - loss: 0.0776 - val_loss: 0.0525\n",
      "Train_loss: 0.07764573395252228, Val_loss : 0.05245006084442139, F1_overall : 0.9957092377587076, loss_overall: 0.00851305334846765 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0766 - val_loss: 0.0545\n",
      "Train_loss: 0.07655765861272812, Val_loss : 0.05449512228369713, F1_overall : 0.9954705427457663, loss_overall: 0.008986000756715852 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 55s 343ms/step - loss: 0.0757 - val_loss: 0.0526\n",
      "Train_loss: 0.0757092535495758, Val_loss : 0.052603550255298615, F1_overall : 0.9952002020967536, loss_overall: 0.009490477992180602 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 0.0750 - val_loss: 0.0540\n",
      "Train_loss: 0.07502512633800507, Val_loss : 0.05398420989513397, F1_overall : 0.9951067053920948, loss_overall: 0.009742716609912978 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 52s 325ms/step - loss: 0.0742 - val_loss: 0.0530\n",
      "Train_loss: 0.0741969496011734, Val_loss : 0.052974894642829895, F1_overall : 0.9951224132215749, loss_overall: 0.00971118678269643 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 320ms/step - loss: 0.0736 - val_loss: 0.0531\n",
      "Train_loss: 0.07361648231744766, Val_loss : 0.053110770881175995, F1_overall : 0.995170302092869, loss_overall: 0.009553537646613696 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 318ms/step - loss: 0.0729 - val_loss: 0.0527\n",
      "Train_loss: 0.07289670407772064, Val_loss : 0.05266739800572395, F1_overall : 0.9948709855598515, loss_overall: 0.01021566401816118 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 54s 335ms/step - loss: 0.0722 - val_loss: 0.0521\n",
      "Train_loss: 0.07219678908586502, Val_loss : 0.05209697410464287, F1_overall : 0.9951544422873556, loss_overall: 0.009616597301046791 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 52s 326ms/step - loss: 0.0719 - val_loss: 0.0538\n",
      "Train_loss: 0.07191520929336548, Val_loss : 0.053753018379211426, F1_overall : 0.9950605204601763, loss_overall: 0.009837306091562617 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 317ms/step - loss: 0.0716 - val_loss: 0.0529\n",
      "Train_loss: 0.07161211967468262, Val_loss : 0.05285701900720596, F1_overall : 0.9950906880929453, loss_overall: 0.009805776264346071 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 54s 336ms/step - loss: 0.0709 - val_loss: 0.0524\n",
      "Train_loss: 0.07087037712335587, Val_loss : 0.05236944183707237, F1_overall : 0.9951536773643581, loss_overall: 0.009648127128263337 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 310ms/step - loss: 0.0705 - val_loss: 0.0525\n",
      "Train_loss: 0.07048990577459335, Val_loss : 0.0524846650660038, F1_overall : 0.9951879841597903, loss_overall: 0.009553537646613696 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 322ms/step - loss: 0.0704 - val_loss: 0.0515\n",
      "Train_loss: 0.07038560509681702, Val_loss : 0.051530804485082626, F1_overall : 0.9954242797185141, loss_overall: 0.009112120065582041 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 53s 328ms/step - loss: 0.0697 - val_loss: 0.0522\n",
      "Train_loss: 0.06967207789421082, Val_loss : 0.05220913887023926, F1_overall : 0.9954525358428598, loss_overall: 0.0090175305839324 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 320ms/step - loss: 0.0693 - val_loss: 0.0532\n",
      "Train_loss: 0.06934354454278946, Val_loss : 0.053232450038194656, F1_overall : 0.9950451303414755, loss_overall: 0.009868835918779165 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 319ms/step - loss: 0.0690 - val_loss: 0.0521\n",
      "Train_loss: 0.06895752251148224, Val_loss : 0.05207331106066704, F1_overall : 0.9950127836873834, loss_overall: 0.009931895573212259 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 318ms/step - loss: 0.0687 - val_loss: 0.0530\n",
      "Train_loss: 0.06870148330926895, Val_loss : 0.05304510518908501, F1_overall : 0.9952162174963293, loss_overall: 0.009553537646613696 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 54s 338ms/step - loss: 0.0684 - val_loss: 0.0531\n",
      "Train_loss: 0.06840433925390244, Val_loss : 0.05307949706912041, F1_overall : 0.9950754466822398, loss_overall: 0.009805776264346071 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0680 - val_loss: 0.0518\n",
      "Train_loss: 0.06798127293586731, Val_loss : 0.05184789001941681, F1_overall : 0.9948073675405229, loss_overall: 0.010341783327027367 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 54s 336ms/step - loss: 0.0679 - val_loss: 0.0545\n",
      "Train_loss: 0.06787624210119247, Val_loss : 0.054535556584596634, F1_overall : 0.9950927021696251, loss_overall: 0.009742716609912978 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 311ms/step - loss: 0.0676 - val_loss: 0.0532\n",
      "Train_loss: 0.06760171800851822, Val_loss : 0.05316399782896042, F1_overall : 0.9946645619573794, loss_overall: 0.010562492117543195 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 55s 342ms/step - loss: 0.0671 - val_loss: 0.0544\n",
      "Train_loss: 0.06708335876464844, Val_loss : 0.05444267392158508, F1_overall : 0.9952507928493665, loss_overall: 0.009395888510530963 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 311ms/step - loss: 0.0669 - val_loss: 0.0539\n",
      "Train_loss: 0.06692168116569519, Val_loss : 0.053869374096393585, F1_overall : 0.9951716738197424, loss_overall: 0.009585067473830243 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 55s 343ms/step - loss: 0.0666 - val_loss: 0.0527\n",
      "Train_loss: 0.06664241850376129, Val_loss : 0.05268247053027153, F1_overall : 0.9948713093152802, loss_overall: 0.010152604363728087 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 52s 324ms/step - loss: 0.0666 - val_loss: 0.0532\n",
      "Train_loss: 0.06659635901451111, Val_loss : 0.05322269722819328, F1_overall : 0.9951559714091861, loss_overall: 0.009616597301046791 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 52s 324ms/step - loss: 0.0663 - val_loss: 0.0537\n",
      "Train_loss: 0.06631945073604584, Val_loss : 0.05369679629802704, F1_overall : 0.9949184105040557, loss_overall: 0.010121074536511539 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 52s 324ms/step - loss: 0.0661 - val_loss: 0.0532\n",
      "Train_loss: 0.06606191396713257, Val_loss : 0.05324046313762665, F1_overall : 0.9947923242014897, loss_overall: 0.01040484298146046 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 52s 322ms/step - loss: 0.0660 - val_loss: 0.0548\n",
      "Train_loss: 0.06596700847148895, Val_loss : 0.05483371391892433, F1_overall : 0.9948243759270362, loss_overall: 0.010310253499810821 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 55s 342ms/step - loss: 0.0657 - val_loss: 0.0530\n",
      "Train_loss: 0.0657113641500473, Val_loss : 0.05303036794066429, F1_overall : 0.9950463810184892, loss_overall: 0.009805776264346071 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.0653 - val_loss: 0.0527\n",
      "Train_loss: 0.06530498713254929, Val_loss : 0.052724745124578476, F1_overall : 0.9946502122555904, loss_overall: 0.010625551771976289 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 52s 326ms/step - loss: 0.0653 - val_loss: 0.0539\n",
      "Train_loss: 0.06527592986822128, Val_loss : 0.053941115736961365, F1_overall : 0.9948224151539068, loss_overall: 0.010278723672594274 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 315ms/step - loss: 0.0652 - val_loss: 0.0553\n",
      "Train_loss: 0.06516385078430176, Val_loss : 0.05528760701417923, F1_overall : 0.9949507700075737, loss_overall: 0.0100264850548619 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 55s 342ms/step - loss: 0.0651 - val_loss: 0.0526\n",
      "Train_loss: 0.0651065856218338, Val_loss : 0.052616044878959656, F1_overall : 0.9951846413741927, loss_overall: 0.009585067473830243 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0648 - val_loss: 0.0536\n",
      "Train_loss: 0.06477756798267365, Val_loss : 0.05363340675830841, F1_overall : 0.9946669191201993, loss_overall: 0.010625551771976289 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 55s 342ms/step - loss: 0.0646 - val_loss: 0.0522\n",
      "Train_loss: 0.0645671933889389, Val_loss : 0.052157334983348846, F1_overall : 0.9947293672084582, loss_overall: 0.010436372808677008 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 50s 311ms/step - loss: 0.0644 - val_loss: 0.0522\n",
      "Train_loss: 0.06443500518798828, Val_loss : 0.052186910063028336, F1_overall : 0.9947594393231468, loss_overall: 0.01040484298146046 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 322ms/step - loss: 0.0644 - val_loss: 0.0551\n",
      "Train_loss: 0.06436964869499207, Val_loss : 0.05510789528489113, F1_overall : 0.994539313784287, loss_overall: 0.010846260562492117 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 319ms/step - loss: 0.0640 - val_loss: 0.0551\n",
      "Train_loss: 0.06403587758541107, Val_loss : 0.055123887956142426, F1_overall : 0.9951248757553286, loss_overall: 0.00971118678269643 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "160/160 [==============================] - 51s 317ms/step - loss: 0.0640 - val_loss: 0.0528\n",
      "Train_loss: 0.06398347020149231, Val_loss : 0.052847541868686676, F1_overall : 0.9947908445146013, loss_overall: 0.010373313154243915 Best_loss: 0.00851305334846765, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-s1x2-[2, 2, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_12_53_46\n",
      "saved model for the best_epoch: 21 with best_f1: 0.00851305334846765 f1_for_best_er: 0.9957092377587076\n",
      "best_conf_mat: [[8.74923163e-01 1.21415399e-01 3.34072748e-03 3.20709838e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.62541241e-02 8.72899563e-01 8.89920458e-02 1.83508530e-03\n",
      "  1.91820763e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.01160264e-03 6.37089751e-02 8.65197350e-01 6.79401131e-02\n",
      "  2.13756037e-03 4.39827236e-06 0.00000000e+00 0.00000000e+00]\n",
      " [3.70477855e-05 2.22286713e-03 9.08720431e-02 8.43584250e-01\n",
      "  6.21476601e-02 1.12378283e-03 1.23492618e-05 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.70614872e-03 9.75353365e-02\n",
      "  8.55710451e-01 4.17569622e-02 2.91101983e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.11111111e-04 9.44444444e-03\n",
      "  1.22666667e-01 8.28777778e-01 3.90000000e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.25203252e-02 3.59349593e-01 5.18699187e-01 8.94308943e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.33333333e-01 8.66666667e-01]]\n",
      "best_conf_mat_diag: [0.87492316 0.87289956 0.86519735 0.84358425 0.85571045 0.82877778\n",
      " 0.51869919 0.86666667]\n",
      "\n",
      "\n",
      "METRICS FOR ALL FOUR FOLDS: avg_er: [0.011850464244991041, 0.020695296523517384, 0.008793356130923302, 0.011380849060465877, 0.00851305334846765], avg_f1: [0.9940161198404298, 0.9894455852156057, 0.9955604431410882, 0.9942611190817789, 0.9957092377587076]\n",
      "MODEL AVERAGE OVER FOUR FOLDS: avg_er: 0.01224660386167305, avg_f1: 0.993798501007522\n"
     ]
    }
   ],
   "source": [
    "avg_er = list()\n",
    "avg_f1 = list()\n",
    "\n",
    "\n",
    "for fold in [1, 2, 3, 4, 5]:\n",
    "    print('\\n\\n----------------------------------------------')\n",
    "    print('FOLD: {}'.format(fold))\n",
    "    print('----------------------------------------------\\n')\n",
    "    \n",
    "    K.clear_session() #モデルを初期化してメモリーリセット\n",
    "    \n",
    "    # Load feature and labels, pre-process it\n",
    "    X, Y, X_test, Y_test = load_data(feat_folder, is_mono, fold)\n",
    "    print(\"load.data_X_test:\",X_test.shape)\n",
    "    X, Y, X_test, Y_test = preprocess_data(X, Y, X_test, Y_test, seq_len, nb_ch)\n",
    "    X=X.transpose(0,2,3,1) #(time, mel, ch)\n",
    "    X_test=X_test.transpose(0,2,3,1) #(time, mel, ch)\n",
    "    print(X.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y.shape)\n",
    "    print(Y_test.shape)\n",
    "\n",
    "    # Load model\n",
    "    model = get_model(X, Y, cnn_nb_filt, cnn_pool_size, rnn_nb, fc_nb)\n",
    "\n",
    "    # Training\n",
    "    best_epoch, pat_cnt, best_er, f1_for_best_er, best_conf_mat = 0, 0, 99999, None, None\n",
    "    tr_loss, val_loss, f1_overall_1sec_list, er_overall_1sec_list = [0] * nb_epoch, [0] * nb_epoch, [0] * nb_epoch, [0] * nb_epoch\n",
    "    posterior_thresh = 0.5\n",
    "    \n",
    "    print(Y.shape)\n",
    "    training_generator = SpecaugmentGenerator(X, Y, batch_size=batch_size)()\n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch : {} '.format(i), end='')\n",
    "        \n",
    "        hist = model.fit(\n",
    "                        x=training_generator,\n",
    "                        steps_per_epoch=X.shape[0] // batch_size * STEP,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        epochs=1,\n",
    "                        # validation_steps=X_valid.shape[0] // BATCH_SIZE,\n",
    "                        validation_steps=None,\n",
    "                        verbose=1,\n",
    "                        shuffle=True)\n",
    "\n",
    "        val_loss[i] = hist.history.get('val_loss')[-1]\n",
    "        tr_loss[i] = hist.history.get('loss')[-1]\n",
    "\n",
    "        # Calculate the predictions on test data, in order to calculate ER and F scores\n",
    "        pred = model.predict(X_test)\n",
    "        pred_thresh = pred > posterior_thresh\n",
    "        score_list = metrics.compute_scores(pred_thresh, Y_test, frames_in_1_sec=frames_1_sec)\n",
    "\n",
    "        f1_overall_1sec_list[i] = score_list['f1_overall_1sec']\n",
    "        er_overall_1sec_list[i] = score_list['er_overall_1sec']\n",
    "        pat_cnt = pat_cnt + 1\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        test_pred_cnt = np.sum(pred_thresh, 2)\n",
    "        Y_test_cnt = np.sum(Y_test, 2)\n",
    "        conf_mat = confusion_matrix(Y_test_cnt.reshape(-1), test_pred_cnt.reshape(-1))\n",
    "        conf_mat = conf_mat / (utils.eps + np.sum(conf_mat, 1)[:, None].astype('float'))\n",
    "\n",
    "        if er_overall_1sec_list[i] < best_er:\n",
    "            best_conf_mat = conf_mat\n",
    "            best_er = er_overall_1sec_list[i]\n",
    "            f1_for_best_er = f1_overall_1sec_list[i]\n",
    "            model.save(os.path.join(__models_dir, '{}_fold{}_model.h5'.format(__fig_name, fold)))\n",
    "            best_epoch = i\n",
    "            pat_cnt = 0\n",
    "\n",
    "        print('Train_loss: {}, Val_loss : {}, F1_overall : {}, loss_overall: {} Best_loss: {}, best_epoch: {}'.format(\n",
    "                tr_loss[i], val_loss[i], f1_overall_1sec_list[i], er_overall_1sec_list[i], best_er, best_epoch))\n",
    "        plot_functions(nb_epoch, tr_loss, val_loss, f1_overall_1sec_list, er_overall_1sec_list, '_fold_{}'.format(fold))\n",
    "\n",
    "        # Early stopping\n",
    "        if pat_cnt > patience:\n",
    "            break\n",
    "            \n",
    "    avg_er.append(best_er)\n",
    "    avg_f1.append(f1_for_best_er)\n",
    "    print('saved model for the best_epoch: {} with best_f1: {} f1_for_best_er: {}'.format(\n",
    "        best_epoch, best_er, f1_for_best_er))\n",
    "    print('best_conf_mat: {}'.format(best_conf_mat))\n",
    "    print('best_conf_mat_diag: {}'.format(np.diag(best_conf_mat)))\n",
    "\n",
    "print('\\n\\nMETRICS FOR ALL FOUR FOLDS: avg_er: {}, avg_f1: {}'.format(avg_er, avg_f1))\n",
    "print('MODEL AVERAGE OVER FOUR FOLDS: avg_er: {}, avg_f1: {}'.format(np.mean(avg_er), np.mean(avg_f1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
