{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35ba431-26cb-4a4d-ae13-b2066a99234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 08:38:28.214460: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-01 08:38:28.692540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 22319 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7274336705582571117,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23403757568\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 9021967592445404728\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:02:00.0, compute capability: 8.6\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "#TensorFlowがGPUを認識しているか確認\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be3a99-abc9-43f2-b020-d8a785014616",
   "metadata": {},
   "source": [
    "# モデル構造の定義\n",
    "<img src=\"images/CRNN_SED_DCASE2017_task3.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa12d71-7f92-4f0b-a1df-30194a335ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed, Conv2D, MaxPooling2D, Input, GRU, Dense, Activation, Dropout, Reshape, Permute, LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import metrics\n",
    "import utils\n",
    "from IPython import embed\n",
    "import keras.backend as K\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "\n",
    "plot.switch_backend('agg')\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "def load_data(_feat_folder, _mono, _fold=None):\n",
    "    \n",
    "    # Load name\n",
    "    feat_file_fold = os.path.join(_feat_folder, 'mbe123_mon_snr_0-28_step2_fold{}.npz'.format(_fold))\n",
    "        \n",
    "    dmp = np.load(feat_file_fold)\n",
    "    _X_train, _Y_train, _X_test, _Y_test = dmp['arr_0'],  dmp['arr_1'],  dmp['arr_2'],  dmp['arr_3']\n",
    "    return _X_train, _Y_train, _X_test, _Y_test\n",
    "\n",
    "mel_filt = 40\n",
    "\n",
    "def get_model(data_in, data_out, _cnn_nb_filt, _cnn_pool_size, _rnn_nb, _fc_nb):\n",
    "    \n",
    "    # input_shape (ch, time, mel)\n",
    "    spec_start = Input(shape=(data_in.shape[-3], data_in.shape[-2], data_in.shape[-1])) #default\n",
    "\n",
    "    spec_x = spec_start\n",
    "    for _i, _cnt in enumerate(_cnn_pool_size):\n",
    "        spec_x = Conv2D(filters=_cnn_nb_filt, kernel_size=(3, 3), padding='same', data_format=\"channels_last\")(spec_x)\n",
    "        spec_x = BatchNormalization(axis=3)(spec_x)\n",
    "        spec_x = Activation('relu')(spec_x)\n",
    "        spec_x = MaxPooling2D(pool_size=(_cnn_pool_size[_i], 1))(spec_x) #cnn_pool_size [5, 2, 2]\n",
    "        spec_x = Dropout(dropout_rate)(spec_x)\n",
    "    spec_x = Permute((1, 3, 2))(spec_x)\n",
    "    spec_x = Reshape((data_in.shape[-3], -1))(spec_x) #[-2]:time\n",
    "\n",
    "    for _r in _rnn_nb:\n",
    "        spec_x = Bidirectional(\n",
    "            GRU(_r, activation='tanh', dropout=dropout_rate, return_sequences=True),\n",
    "            merge_mode='mul')(spec_x)\n",
    " \n",
    "    for _f in _fc_nb:\n",
    "        spec_x = TimeDistributed(Dense(_f))(spec_x)\n",
    "        spec_x = Dropout(dropout_rate)(spec_x)\n",
    "\n",
    "    spec_x = TimeDistributed(Dense(data_out.shape[-1]))(spec_x)\n",
    "    out = Activation('sigmoid', name='strong_out')(spec_x)\n",
    "\n",
    "    _model = Model(inputs=spec_start, outputs=out)\n",
    "    _model.compile(optimizer=\"Adam\", loss='binary_crossentropy')\n",
    "    _model.summary()\n",
    "    \n",
    "    return _model\n",
    "\n",
    "\n",
    "def plot_functions(_nb_epoch, _tr_loss, _val_loss, _f1, _er, extension=''):\n",
    "    plot.figure()\n",
    "\n",
    "    plot.subplot(211)\n",
    "    plot.plot(range(_nb_epoch), _tr_loss, label='train loss')\n",
    "    plot.plot(range(_nb_epoch), _val_loss, label='val loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "\n",
    "    plot.subplot(212)\n",
    "    plot.plot(range(_nb_epoch), _f1, label='f')\n",
    "    plot.plot(range(_nb_epoch), _er, label='er')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "\n",
    "    plot.savefig(__models_dir + __fig_name + extension)\n",
    "    plot.close()\n",
    "    print('figure name : {}'.format(__fig_name))\n",
    "\n",
    "\n",
    "def preprocess_data(_X, _Y, _X_test, _Y_test, _seq_len, _nb_ch):\n",
    "    # split into sequences\n",
    "    _X = utils.split_in_seqs(_X, _seq_len)\n",
    "    _Y = utils.split_in_seqs(_Y, _seq_len)\n",
    "\n",
    "    _X_test = utils.split_in_seqs(_X_test, _seq_len)\n",
    "    _Y_test = utils.split_in_seqs(_Y_test, _seq_len)\n",
    "\n",
    "    _X = utils.split_multi_channels(_X, _nb_ch)\n",
    "    _X_test = utils.split_multi_channels(_X_test, _nb_ch)\n",
    "    return _X, _Y, _X_test, _Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b31f4dd-a90b-479a-b47e-4b41c8dd93d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UNIQUE ID: mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "TRAINING PARAMETERS: nb_ch: 1, seq_len: 256, batch_size: 480, nb_epoch: 150, frames_1_sec: 93\n",
      "MODEL PARAMETERS:\n",
      " cnn_nb_filt: 128, cnn_pool_size: [5, 2, 2], rnn_nb: [32, 32], fc_nb: [32], dropout_rate: 0.5\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "# MAIN SCRIPT STARTS HERE\n",
    "#######################################################################################\n",
    "\n",
    "is_mono = True  # True: mono-channel input, False: binaural input\n",
    "\n",
    "feat_folder = 'feat/'\n",
    "\n",
    "\n",
    "nb_ch = 1 if is_mono else 2\n",
    "batch_size = 480 #560    # 576でOOM # Decrease this if you want to run on smaller GPU's\n",
    "seq_len = 256       # Frame sequence length. Input to the CRNN.\n",
    "nb_epoch = 150      # Training epochs\n",
    "patience = int(0.25 * nb_epoch)  # Patience for early stopping\n",
    "\n",
    "STEP = 10 #generatorで何倍に増量するか\n",
    "\n",
    "\n",
    "# Number of frames in 1 second, required to calculate F and ER for 1 sec segments.\n",
    "# Make sure the nfft and sr are the same as in feature.py\n",
    "sr = 48000\n",
    "nfft = 1024\n",
    "frames_1_sec = int(sr/(nfft/2.0))\n",
    "\n",
    "# Folder for saving model and training curves\n",
    "__models_dir = 'models/'\n",
    "utils.create_folder(__models_dir)\n",
    "\n",
    "# CRNN model definition\n",
    "cnn_nb_filt = 128            # CNN filter size\n",
    "cnn_pool_size = [5, 2, 2]   # Maxpooling across frequency. Length of cnn_pool_size =  number of CNN layers\n",
    "rnn_nb = [32, 32]           # Number of RNN nodes.  Length of rnn_nb =  number of RNN layers\n",
    "fc_nb = [32]                # Number of FC nodes.  Length of fc_nb =  number of FC layers\n",
    "dropout_rate = 0.5          # Dropout after each layer\n",
    "\n",
    "__fig_name = f'mbf{mel_filt}_cnn-f{cnn_nb_filt}-{cnn_pool_size}_bigru{rnn_nb}_fc{fc_nb}_spec{STEP}_e{nb_epoch}p{patience}_batch{batch_size}_{time.strftime(\"%Y_%m_%d_%H_%M_%S\")}'\n",
    "\n",
    "print('\\n\\nUNIQUE ID: {}'.format(__fig_name))\n",
    "print('TRAINING PARAMETERS: nb_ch: {}, seq_len: {}, batch_size: {}, nb_epoch: {}, frames_1_sec: {}'.format(nb_ch, seq_len, batch_size, nb_epoch, frames_1_sec))\n",
    "print('MODEL PARAMETERS:\\n cnn_nb_filt: {}, cnn_pool_size: {}, rnn_nb: {}, fc_nb: {}, dropout_rate: {}'.format(cnn_nb_filt, cnn_pool_size, rnn_nb, fc_nb, dropout_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17022d1d-c26f-4919-8a69-ad4d7f9844f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load.data_X_test: (506265, 40)\n",
      "(8490, 256, 7)\n",
      "(8490, 1, 256, 40)\n",
      "(8490, 256, 7)\n",
      "(1977, 1, 256, 40)\n",
      "(1977, 256, 7)\n"
     ]
    }
   ],
   "source": [
    "X, Y, X_test, Y_test = load_data(feat_folder, is_mono, 1)\n",
    "print(\"load.data_X_test:\",X_test.shape)\n",
    "X, Y, X_test, Y_test = preprocess_data(X, Y, X_test, Y_test, seq_len, nb_ch)\n",
    "\n",
    "print(Y.shape)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11782d24-5f0d-44e1-9646-1605645bd45d",
   "metadata": {},
   "source": [
    "## SpecAugmentのジェネレータ\n",
    "* ランダムに周波数方向と時間方向にマスクして水増しすることで汎化性能を高める事を目的とする\n",
    "* 引用論文: https://arxiv.org/abs/1904.08779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55ef4b-1e62-41d8-89f7-69eee47e2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# class data generator\n",
    "class SpecaugmentGenerator():\n",
    "    def __init__(self, x_train, y_train, batch_size=16, alpha=0.2, shuffle=True):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_num = len(x_train)\n",
    "\n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            indexes = self.__get_exploration_order()\n",
    "            itr_num = int(len(indexes) // (self.batch_size * 2))\n",
    "\n",
    "            for i in range(itr_num):\n",
    "                batch_ids = indexes[i * self.batch_size * 2:(i + 1) * self.batch_size * 2]\n",
    "                x, y = self.__data_generation(batch_ids)\n",
    "\n",
    "                yield x, y\n",
    "\n",
    "    def __get_exploration_order(self):\n",
    "        indexes = np.arange(self.sample_num)\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indexes)\n",
    "\n",
    "        return indexes\n",
    "\n",
    "    def __data_generation(self, batch_ids):\n",
    "        \n",
    "        x1 = self.x_train[batch_ids[:self.batch_size]]\n",
    "        y = self.y_train[batch_ids[:self.batch_size]]\n",
    "\n",
    "        for j, _ in enumerate(x1): # shape(batch, time, freq, ch) = x1.shape: (64, 256, 40, 1)\n",
    "            # 時間軸のマスク\n",
    "            k = random.randint(0, 50) # max time mask1 width\n",
    "            l = random.randint(10, 200) # time mask1 start\n",
    "            x1[j, l:l+k, :, :] = 0\n",
    "            \n",
    "            # 周波数軸のマスク\n",
    "            m = random.randint(1, 8) # max freq mask width\n",
    "            n = random.randint(5, 31)  # freq mask start\n",
    "            x1[j, :, n:n+m, :] = 0\n",
    "\n",
    "        x = x1\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606b624-8062-4d72-8de5-b97705c0a6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------\n",
      "FOLD: 1\n",
      "----------------------------------------------\n",
      "\n",
      "load.data_X_test: (506265, 40)\n",
      "(8490, 256, 40, 1)\n",
      "(1977, 256, 40, 1)\n",
      "(8490, 256, 7)\n",
      "(1977, 256, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 08:39:02.515082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22319 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 40, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 40, 128)      1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 40, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 40, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 51, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 51, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 51, 40, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 51, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 51, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 40, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 25, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 25, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 12, 128, 40)       0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 256, 240)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256, 32)           52608     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256, 32)           12672     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 256, 32)           1056      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 32)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 256, 7)            231       \n",
      "_________________________________________________________________\n",
      "strong_out (Activation)      (None, 256, 7)            0         \n",
      "=================================================================\n",
      "Total params: 364,551\n",
      "Trainable params: 363,783\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "(8490, 256, 7)\n",
      "Epoch : 0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 08:39:03.659311: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-01 08:39:08.230922: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n",
      "2022-05-01 08:39:10.132727: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 45s 224ms/step - loss: 0.4492 - val_loss: 0.2657\n",
      "Train_loss: 0.44923004508018494, Val_loss : 0.2657454013824463, F1_overall : 0.9243848641240334, loss_overall: 0.1370337188467177 Best_loss: 0.1370337188467177, best_epoch: 0\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 218ms/step - loss: 0.2955 - val_loss: 0.2088\n",
      "Train_loss: 0.2955048382282257, Val_loss : 0.2088337540626526, F1_overall : 0.9729038543506057, loss_overall: 0.05289949503176413 Best_loss: 0.05289949503176413, best_epoch: 1\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.2520 - val_loss: 0.1538\n",
      "Train_loss: 0.2520159184932709, Val_loss : 0.15381161868572235, F1_overall : 0.9787312064539786, loss_overall: 0.041130477276429385 Best_loss: 0.041130477276429385, best_epoch: 2\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.2170 - val_loss: 0.1308\n",
      "Train_loss: 0.21704606711864471, Val_loss : 0.13084080815315247, F1_overall : 0.9814712896716198, loss_overall: 0.03567356246945757 Best_loss: 0.03567356246945757, best_epoch: 3\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1955 - val_loss: 0.1174\n",
      "Train_loss: 0.1955176144838333, Val_loss : 0.11741673946380615, F1_overall : 0.9829742169361735, loss_overall: 0.032985828310799804 Best_loss: 0.032985828310799804, best_epoch: 4\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1799 - val_loss: 0.1159\n",
      "Train_loss: 0.17991307377815247, Val_loss : 0.11585835367441177, F1_overall : 0.9826648469169501, loss_overall: 0.03375956996253462 Best_loss: 0.032985828310799804, best_epoch: 4\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.1677 - val_loss: 0.1082\n",
      "Train_loss: 0.1677192896604538, Val_loss : 0.10820873826742172, F1_overall : 0.9828815977175464, loss_overall: 0.033352337514253136 Best_loss: 0.032985828310799804, best_epoch: 4\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.1584 - val_loss: 0.1025\n",
      "Train_loss: 0.15840227901935577, Val_loss : 0.10250158607959747, F1_overall : 0.9832495471475382, loss_overall: 0.03257859586251832 Best_loss: 0.03257859586251832, best_epoch: 7\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1503 - val_loss: 0.0923\n",
      "Train_loss: 0.1502918303012848, Val_loss : 0.09234298020601273, F1_overall : 0.9841949627816864, loss_overall: 0.030827496334907965 Best_loss: 0.030827496334907965, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1435 - val_loss: 0.0922\n",
      "Train_loss: 0.14345131814479828, Val_loss : 0.09218138456344604, F1_overall : 0.9842264872896015, loss_overall: 0.030908942824564262 Best_loss: 0.030827496334907965, best_epoch: 8\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.1379 - val_loss: 0.0888\n",
      "Train_loss: 0.13785327970981598, Val_loss : 0.08883532136678696, F1_overall : 0.9848265748793253, loss_overall: 0.02972796872454797 Best_loss: 0.02972796872454797, best_epoch: 10\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1326 - val_loss: 0.0791\n",
      "Train_loss: 0.13263744115829468, Val_loss : 0.07907533645629883, F1_overall : 0.9865390489766825, loss_overall: 0.026347939403811697 Best_loss: 0.026347939403811697, best_epoch: 11\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1286 - val_loss: 0.0783\n",
      "Train_loss: 0.12862607836723328, Val_loss : 0.07834792882204056, F1_overall : 0.9857885615251298, loss_overall: 0.027732529727968726 Best_loss: 0.026347939403811697, best_epoch: 11\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1254 - val_loss: 0.0766\n",
      "Train_loss: 0.12543846666812897, Val_loss : 0.07659676671028137, F1_overall : 0.9864443402572516, loss_overall: 0.026510832383124287 Best_loss: 0.026347939403811697, best_epoch: 11\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.1225 - val_loss: 0.0727\n",
      "Train_loss: 0.12253912538290024, Val_loss : 0.07271544635295868, F1_overall : 0.9873216469629025, loss_overall: 0.024759732855513927 Best_loss: 0.024759732855513927, best_epoch: 14\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.1200 - val_loss: 0.0700\n",
      "Train_loss: 0.12003979086875916, Val_loss : 0.07002212852239609, F1_overall : 0.9877785472766528, loss_overall: 0.02390454471412282 Best_loss: 0.02390454471412282, best_epoch: 15\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1179 - val_loss: 0.0681\n",
      "Train_loss: 0.11785786598920822, Val_loss : 0.06806270778179169, F1_overall : 0.9876669044949545, loss_overall: 0.024067437693435414 Best_loss: 0.02390454471412282, best_epoch: 15\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.1164 - val_loss: 0.0685\n",
      "Train_loss: 0.11638008803129196, Val_loss : 0.06847026199102402, F1_overall : 0.9879964947319079, loss_overall: 0.023415865776185048 Best_loss: 0.023415865776185048, best_epoch: 17\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1142 - val_loss: 0.0678\n",
      "Train_loss: 0.11418302357196808, Val_loss : 0.06781099736690521, F1_overall : 0.9880981495068067, loss_overall: 0.02317152630721616 Best_loss: 0.02317152630721616, best_epoch: 18\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1125 - val_loss: 0.0671\n",
      "Train_loss: 0.11251160502433777, Val_loss : 0.0671323761343956, F1_overall : 0.9879911105674148, loss_overall: 0.023619482000325785 Best_loss: 0.02317152630721616, best_epoch: 18\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1115 - val_loss: 0.0659\n",
      "Train_loss: 0.1114577129483223, Val_loss : 0.0659121498465538, F1_overall : 0.9885699150384057, loss_overall: 0.022438507900309497 Best_loss: 0.022438507900309497, best_epoch: 20\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1099 - val_loss: 0.0648\n",
      "Train_loss: 0.10985807329416275, Val_loss : 0.06479121744632721, F1_overall : 0.9888506145410814, loss_overall: 0.021909105717543575 Best_loss: 0.021909105717543575, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.1086 - val_loss: 0.0633\n",
      "Train_loss: 0.1085556223988533, Val_loss : 0.06325336545705795, F1_overall : 0.9887576258390972, loss_overall: 0.022112721941684312 Best_loss: 0.021909105717543575, best_epoch: 21\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1071 - val_loss: 0.0625\n",
      "Train_loss: 0.10712088644504547, Val_loss : 0.06247195228934288, F1_overall : 0.9889634631469428, loss_overall: 0.021705489493402834 Best_loss: 0.021705489493402834, best_epoch: 23\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1036 - val_loss: 0.0634\n",
      "Train_loss: 0.10358945280313492, Val_loss : 0.06344403326511383, F1_overall : 0.9892262886702917, loss_overall: 0.021135364065808765 Best_loss: 0.020768854862355433, best_epoch: 24\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.1027 - val_loss: 0.0624\n",
      "Train_loss: 0.10265051573514938, Val_loss : 0.06237029656767845, F1_overall : 0.9890190485891819, loss_overall: 0.021501873269262096 Best_loss: 0.020768854862355433, best_epoch: 24\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1020 - val_loss: 0.0619\n",
      "Train_loss: 0.10197379440069199, Val_loss : 0.06190496310591698, F1_overall : 0.9895444818098441, loss_overall: 0.02044306890373025 Best_loss: 0.02044306890373025, best_epoch: 29\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1009 - val_loss: 0.0651\n",
      "Train_loss: 0.10094233602285385, Val_loss : 0.06511398404836655, F1_overall : 0.9888861748900829, loss_overall: 0.021827659227887278 Best_loss: 0.02044306890373025, best_epoch: 29\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.1005 - val_loss: 0.0634\n",
      "Train_loss: 0.10054834932088852, Val_loss : 0.06341070681810379, F1_overall : 0.9890638046555199, loss_overall: 0.0214204267796058 Best_loss: 0.02044306890373025, best_epoch: 29\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0995 - val_loss: 0.0638\n",
      "Train_loss: 0.09954303503036499, Val_loss : 0.06375094503164291, F1_overall : 0.9890159157139654, loss_overall: 0.021501873269262096 Best_loss: 0.02044306890373025, best_epoch: 29\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0994 - val_loss: 0.0619\n",
      "Train_loss: 0.09942936152219772, Val_loss : 0.06193326786160469, F1_overall : 0.9901199861476092, loss_overall: 0.019343541293370257 Best_loss: 0.019343541293370257, best_epoch: 33\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0987 - val_loss: 0.0603\n",
      "Train_loss: 0.09865264594554901, Val_loss : 0.060305725783109665, F1_overall : 0.9896789691183354, loss_overall: 0.02003583645544877 Best_loss: 0.019343541293370257, best_epoch: 33\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0981 - val_loss: 0.0625\n",
      "Train_loss: 0.09810870885848999, Val_loss : 0.06251291930675507, F1_overall : 0.9890136768512667, loss_overall: 0.021542596514090243 Best_loss: 0.019343541293370257, best_epoch: 33\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0974 - val_loss: 0.0628\n",
      "Train_loss: 0.097373366355896, Val_loss : 0.06283333897590637, F1_overall : 0.9892280437394366, loss_overall: 0.02101319433132432 Best_loss: 0.019343541293370257, best_epoch: 33\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 218ms/step - loss: 0.0972 - val_loss: 0.0614\n",
      "Train_loss: 0.09717133641242981, Val_loss : 0.06143193319439888, F1_overall : 0.9895298622993561, loss_overall: 0.020361622414073955 Best_loss: 0.019343541293370257, best_epoch: 33\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0966 - val_loss: 0.0600\n",
      "Train_loss: 0.09661076217889786, Val_loss : 0.060004133731126785, F1_overall : 0.9894822666123112, loss_overall: 0.020524515393386546 Best_loss: 0.019343541293370257, best_epoch: 33\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0965 - val_loss: 0.0607\n",
      "Train_loss: 0.09648508578538895, Val_loss : 0.060668718069791794, F1_overall : 0.9899327491338903, loss_overall: 0.019750773741651736 Best_loss: 0.019343541293370257, best_epoch: 33\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0956 - val_loss: 0.0620\n",
      "Train_loss: 0.09558922052383423, Val_loss : 0.06201477348804474, F1_overall : 0.9892262886702917, loss_overall: 0.021053917576152468 Best_loss: 0.019343541293370257, best_epoch: 33\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0955 - val_loss: 0.0593\n",
      "Train_loss: 0.09547347575426102, Val_loss : 0.059332720935344696, F1_overall : 0.9901369416367785, loss_overall: 0.01926209480371396 Best_loss: 0.01926209480371396, best_epoch: 41\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0950 - val_loss: 0.0640\n",
      "Train_loss: 0.09498312324285507, Val_loss : 0.06401392072439194, F1_overall : 0.9890257558790593, loss_overall: 0.021298257045121356 Best_loss: 0.01926209480371396, best_epoch: 41\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0948 - val_loss: 0.0630\n",
      "Train_loss: 0.0947505310177803, Val_loss : 0.0629531592130661, F1_overall : 0.9892674582001099, loss_overall: 0.020891024596839877 Best_loss: 0.01926209480371396, best_epoch: 41\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0942 - val_loss: 0.0606\n",
      "Train_loss: 0.09419441968202591, Val_loss : 0.06056232005357742, F1_overall : 0.9895118424536178, loss_overall: 0.020565238638214692 Best_loss: 0.01926209480371396, best_epoch: 41\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      " 46/170 [=======>......................] - ETA: 26s - loss: 0.0942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 37s 220ms/step - loss: 0.0835 - val_loss: 0.0638\n",
      "Train_loss: 0.08351726830005646, Val_loss : 0.06378549337387085, F1_overall : 0.9897335614764114, loss_overall: 0.020280175924417658 Best_loss: 0.017836781234728784, best_epoch: 92\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0836 - val_loss: 0.0619\n",
      "Train_loss: 0.0835522785782814, Val_loss : 0.061857324093580246, F1_overall : 0.9898269148437341, loss_overall: 0.020076559700276917 Best_loss: 0.017836781234728784, best_epoch: 92\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 218ms/step - loss: 0.0831 - val_loss: 0.0588\n",
      "Train_loss: 0.08306669443845749, Val_loss : 0.05883604288101196, F1_overall : 0.9905696885756766, loss_overall: 0.018691969376119888 Best_loss: 0.017836781234728784, best_epoch: 92\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0830 - val_loss: 0.0602\n",
      "Train_loss: 0.0829988643527031, Val_loss : 0.06023921072483063, F1_overall : 0.9907707352851292, loss_overall: 0.018366183417494707 Best_loss: 0.017836781234728784, best_epoch: 92\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0828 - val_loss: 0.0643\n",
      "Train_loss: 0.08275332301855087, Val_loss : 0.0642768070101738, F1_overall : 0.9902572255513431, loss_overall: 0.01926209480371396 Best_loss: 0.017836781234728784, best_epoch: 92\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0829 - val_loss: 0.0591\n",
      "Train_loss: 0.0828951746225357, Val_loss : 0.059107810258865356, F1_overall : 0.99101045722323, loss_overall: 0.017796057989900634 Best_loss: 0.017796057989900634, best_epoch: 109\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0828 - val_loss: 0.0623\n",
      "Train_loss: 0.08278465270996094, Val_loss : 0.0623042993247509, F1_overall : 0.9899940901958385, loss_overall: 0.019791496986479883 Best_loss: 0.017796057989900634, best_epoch: 109\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0831 - val_loss: 0.0655\n",
      "Train_loss: 0.08305761218070984, Val_loss : 0.065531887114048, F1_overall : 0.9897512174249677, loss_overall: 0.02023945267958951 Best_loss: 0.017796057989900634, best_epoch: 109\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0827 - val_loss: 0.0622\n",
      "Train_loss: 0.08265375345945358, Val_loss : 0.06216628476977348, F1_overall : 0.9901385493072534, loss_overall: 0.019465711027854698 Best_loss: 0.017796057989900634, best_epoch: 109\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 218ms/step - loss: 0.0827 - val_loss: 0.0601\n",
      "Train_loss: 0.0826612189412117, Val_loss : 0.06013932451605797, F1_overall : 0.9904059641904139, loss_overall: 0.01905847857957322 Best_loss: 0.017796057989900634, best_epoch: 109\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.0824 - val_loss: 0.0615\n",
      "Train_loss: 0.08240164071321487, Val_loss : 0.0615355558693409, F1_overall : 0.9910541438265441, loss_overall: 0.017755334745072487 Best_loss: 0.017755334745072487, best_epoch: 114\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.0825 - val_loss: 0.0612\n",
      "Train_loss: 0.08252144604921341, Val_loss : 0.061153192073106766, F1_overall : 0.9905301101765674, loss_overall: 0.018814139110604332 Best_loss: 0.017755334745072487, best_epoch: 114\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0822 - val_loss: 0.0623\n",
      "Train_loss: 0.0821620300412178, Val_loss : 0.06233583763241768, F1_overall : 0.9899274121197292, loss_overall: 0.019913666720964326 Best_loss: 0.017755334745072487, best_epoch: 114\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0820 - val_loss: 0.0638\n",
      "Train_loss: 0.08204498887062073, Val_loss : 0.06378468871116638, F1_overall : 0.9898516465601563, loss_overall: 0.020158006189933214 Best_loss: 0.017755334745072487, best_epoch: 114\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0820 - val_loss: 0.0626\n",
      "Train_loss: 0.08197873830795288, Val_loss : 0.06263291090726852, F1_overall : 0.9906850655306657, loss_overall: 0.018447629907151 Best_loss: 0.017755334745072487, best_epoch: 114\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 218ms/step - loss: 0.0822 - val_loss: 0.0624\n",
      "Train_loss: 0.08218439668416977, Val_loss : 0.06235171854496002, F1_overall : 0.9897726346671011, loss_overall: 0.020280175924417658 Best_loss: 0.017755334745072487, best_epoch: 114\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0820 - val_loss: 0.0636\n",
      "Train_loss: 0.08195813000202179, Val_loss : 0.06364557147026062, F1_overall : 0.9894603795894236, loss_overall: 0.020768854862355433 Best_loss: 0.017755334745072487, best_epoch: 114\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 218ms/step - loss: 0.0818 - val_loss: 0.0609\n",
      "Train_loss: 0.08175244927406311, Val_loss : 0.06093154847621918, F1_overall : 0.9903814802738832, loss_overall: 0.01905847857957322 Best_loss: 0.017755334745072487, best_epoch: 114\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      " 17/170 [==>...........................] - ETA: 32s - loss: 0.0816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0963 - val_loss: 0.0665\n",
      "Train_loss: 0.09630373865365982, Val_loss : 0.06654718518257141, F1_overall : 0.9862917976858415, loss_overall: 0.026707566462167688 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.0961 - val_loss: 0.0701\n",
      "Train_loss: 0.09613606333732605, Val_loss : 0.07014923542737961, F1_overall : 0.9844977178337924, loss_overall: 0.030061349693251534 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0951 - val_loss: 0.0717\n",
      "Train_loss: 0.09511783719062805, Val_loss : 0.07173226028680801, F1_overall : 0.9844280336535493, loss_overall: 0.030347648261758692 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0949 - val_loss: 0.0728\n",
      "Train_loss: 0.09493046998977661, Val_loss : 0.07279066741466522, F1_overall : 0.9844793915099188, loss_overall: 0.030265848670756646 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0942 - val_loss: 0.0754\n",
      "Train_loss: 0.09422282129526138, Val_loss : 0.07535357773303986, F1_overall : 0.9842555290635533, loss_overall: 0.03067484662576687 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0938 - val_loss: 0.0775\n",
      "Train_loss: 0.09382575005292892, Val_loss : 0.0774957686662674, F1_overall : 0.9839508456116556, loss_overall: 0.03128834355828221 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0934 - val_loss: 0.0727\n",
      "Train_loss: 0.09335511177778244, Val_loss : 0.07274942100048065, F1_overall : 0.9850101782740114, loss_overall: 0.02903885480572597 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0928 - val_loss: 0.0681\n",
      "Train_loss: 0.09278886020183563, Val_loss : 0.06813458353281021, F1_overall : 0.9861690540290593, loss_overall: 0.02703476482617587 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0922 - val_loss: 0.0740\n",
      "Train_loss: 0.09224942326545715, Val_loss : 0.07401207834482193, F1_overall : 0.9845945279763372, loss_overall: 0.029979550102249487 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0920 - val_loss: 0.0740\n",
      "Train_loss: 0.09200365841388702, Val_loss : 0.07400701195001602, F1_overall : 0.9841432855440988, loss_overall: 0.03083844580777096 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0917 - val_loss: 0.0731\n",
      "Train_loss: 0.09170137345790863, Val_loss : 0.07310892641544342, F1_overall : 0.984740673713651, loss_overall: 0.029734151329243355 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0913 - val_loss: 0.0773\n",
      "Train_loss: 0.09129728376865387, Val_loss : 0.07730650156736374, F1_overall : 0.983918729949823, loss_overall: 0.03132924335378323 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0907 - val_loss: 0.0754\n",
      "Train_loss: 0.09074823558330536, Val_loss : 0.07543325424194336, F1_overall : 0.9843095375010267, loss_overall: 0.030633946830265848 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0903 - val_loss: 0.0707\n",
      "Train_loss: 0.09026171267032623, Val_loss : 0.07074415683746338, F1_overall : 0.9849820236260913, loss_overall: 0.02920245398773006 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0902 - val_loss: 0.0748\n",
      "Train_loss: 0.0902218446135521, Val_loss : 0.07475671172142029, F1_overall : 0.9849041878042267, loss_overall: 0.029447852760736196 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 219ms/step - loss: 0.0899 - val_loss: 0.0743\n",
      "Train_loss: 0.08989458531141281, Val_loss : 0.07425744086503983, F1_overall : 0.9849593161831182, loss_overall: 0.02936605316973415 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "170/170 [==============================] - 37s 220ms/step - loss: 0.0894 - val_loss: 0.0771\n",
      "Train_loss: 0.08944375813007355, Val_loss : 0.07707442343235016, F1_overall : 0.9845793720868153, loss_overall: 0.03002044989775051 Best_loss: 0.024008179959100203, best_epoch: 9\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      "saved model for the best_epoch: 9 with best_f1: 0.024008179959100203 f1_for_best_er: 0.9877863846878969\n",
      "best_conf_mat: [[8.26106411e-01 1.59778718e-01 1.29759193e-02 9.76244712e-04\n",
      "  1.62707452e-04 0.00000000e+00 0.00000000e+00]\n",
      " [2.49601563e-02 8.50067691e-01 1.16009460e-01 8.49142289e-03\n",
      "  4.54132607e-04 1.71370795e-05 0.00000000e+00]\n",
      " [1.31210115e-03 5.94186633e-02 8.40818274e-01 9.40863276e-02\n",
      "  4.29957113e-03 6.50628670e-05 0.00000000e+00]\n",
      " [2.00169374e-04 5.58164601e-03 1.08699669e-01 8.17268458e-01\n",
      "  6.57710370e-02 2.44822542e-03 3.07952883e-05]\n",
      " [0.00000000e+00 4.25029516e-04 1.63636364e-02 1.78417946e-01\n",
      "  7.66186541e-01 3.83707202e-02 2.36127509e-04]\n",
      " [0.00000000e+00 1.29449838e-04 2.58899676e-03 4.01294498e-02\n",
      "  2.57605178e-01 6.79741100e-01 1.98058252e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.76190476e-03\n",
      "  6.19047619e-02 4.69047619e-01 4.64285714e-01]]\n",
      "best_conf_mat_diag: [0.82610641 0.85006769 0.84081827 0.81726846 0.76618654 0.6797411\n",
      " 0.46428571]\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "FOLD: 3\n",
      "----------------------------------------------\n",
      "\n",
      "load.data_X_test: (506265, 40)\n",
      "(8490, 256, 40, 1)\n",
      "(1977, 256, 40, 1)\n",
      "(8490, 256, 7)\n",
      "(1977, 256, 7)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 40, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 40, 128)      1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 40, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 40, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 51, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 51, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 51, 40, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 51, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 51, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 40, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 25, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 25, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 12, 128, 40)       0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 256, 240)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256, 32)           52608     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256, 32)           12672     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 256, 32)           1056      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 32)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 256, 7)            231       \n",
      "_________________________________________________________________\n",
      "strong_out (Activation)      (None, 256, 7)            0         \n",
      "=================================================================\n",
      "Total params: 364,551\n",
      "Trainable params: 363,783\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "(8490, 256, 7)\n",
      "170/170 [==============================] - 42s 224ms/step - loss: 0.4521 - val_loss: 0.2719\n",
      "Train_loss: 0.4520922899246216, Val_loss : 0.27189844846725464, F1_overall : 0.8795079928550432, loss_overall: 0.20985995766161863 Best_loss: 0.20985995766161863, best_epoch: 0\n",
      "figure name : mbf40_cnn-f128-[5, 2, 2]_bigru[32, 32]_fc[32]_spec10_e150p37_batch480_2022_05_01_08_38_46\n",
      " 64/170 [==========>...................] - ETA: 22s - loss: 0.3201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_er = list()\n",
    "avg_f1 = list()\n",
    "\n",
    "\n",
    "for fold in [1, 2, 3, 4, 5]:\n",
    "    print('\\n\\n----------------------------------------------')\n",
    "    print('FOLD: {}'.format(fold))\n",
    "    print('----------------------------------------------\\n')\n",
    "    \n",
    "    K.clear_session() #モデルを初期化してメモリーリセット\n",
    "    \n",
    "    # Load feature and labels, pre-process it\n",
    "    X, Y, X_test, Y_test = load_data(feat_folder, is_mono, fold)\n",
    "    print(\"load.data_X_test:\",X_test.shape)\n",
    "    X, Y, X_test, Y_test = preprocess_data(X, Y, X_test, Y_test, seq_len, nb_ch)\n",
    "    X=X.transpose(0,2,3,1) #(time, mel, ch)\n",
    "    X_test=X_test.transpose(0,2,3,1) #(time, mel, ch)\n",
    "    print(X.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y.shape)\n",
    "    print(Y_test.shape)\n",
    "\n",
    "    # Load model\n",
    "    model = get_model(X, Y, cnn_nb_filt, cnn_pool_size, rnn_nb, fc_nb)\n",
    "\n",
    "    # Training\n",
    "    best_epoch, pat_cnt, best_er, f1_for_best_er, best_conf_mat = 0, 0, 99999, None, None\n",
    "    tr_loss, val_loss, f1_overall_1sec_list, er_overall_1sec_list = [0] * nb_epoch, [0] * nb_epoch, [0] * nb_epoch, [0] * nb_epoch\n",
    "    posterior_thresh = 0.5\n",
    "    \n",
    "    print(Y.shape)\n",
    "    training_generator = SpecaugmentGenerator(X, Y, batch_size=batch_size)()\n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch : {} '.format(i), end='')\n",
    "\n",
    "        hist = model.fit(\n",
    "                        x=training_generator,\n",
    "                        steps_per_epoch=X.shape[0] // batch_size * STEP,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        epochs=1,\n",
    "                        # validation_steps=X_valid.shape[0] // BATCH_SIZE,\n",
    "                        validation_steps=None,\n",
    "                        verbose=1,\n",
    "                        shuffle=True)\n",
    "\n",
    "        val_loss[i] = hist.history.get('val_loss')[-1]\n",
    "        tr_loss[i] = hist.history.get('loss')[-1]\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        pred_thresh = pred > posterior_thresh\n",
    "        score_list = metrics.compute_scores(pred_thresh, Y_test, frames_in_1_sec=frames_1_sec)\n",
    "\n",
    "        f1_overall_1sec_list[i] = score_list['f1_overall_1sec']\n",
    "        er_overall_1sec_list[i] = score_list['er_overall_1sec']\n",
    "        pat_cnt = pat_cnt + 1\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        test_pred_cnt = np.sum(pred_thresh, 2)\n",
    "        Y_test_cnt = np.sum(Y_test, 2)\n",
    "        conf_mat = confusion_matrix(Y_test_cnt.reshape(-1), test_pred_cnt.reshape(-1))\n",
    "        conf_mat = conf_mat / (utils.eps + np.sum(conf_mat, 1)[:, None].astype('float'))\n",
    "\n",
    "        if er_overall_1sec_list[i] < best_er:\n",
    "            best_conf_mat = conf_mat\n",
    "            best_er = er_overall_1sec_list[i]\n",
    "            f1_for_best_er = f1_overall_1sec_list[i]\n",
    "            model.save(os.path.join(__models_dir, '{}_fold{}_model.h5'.format(__fig_name, fold)))\n",
    "            best_epoch = i\n",
    "            pat_cnt = 0\n",
    "\n",
    "        print('Train_loss: {}, Val_loss : {}, F1_overall : {}, loss_overall: {} Best_loss: {}, best_epoch: {}'.format(\n",
    "                tr_loss[i], val_loss[i], f1_overall_1sec_list[i], er_overall_1sec_list[i], best_er, best_epoch))\n",
    "        plot_functions(nb_epoch, tr_loss, val_loss, f1_overall_1sec_list, er_overall_1sec_list, '_fold_{}'.format(fold))\n",
    "\n",
    "        # Early stopping\n",
    "        if pat_cnt > patience:\n",
    "            break\n",
    "            \n",
    "    avg_er.append(best_er)\n",
    "    avg_f1.append(f1_for_best_er)\n",
    "    print('saved model for the best_epoch: {} with best_f1: {} f1_for_best_er: {}'.format(\n",
    "        best_epoch, best_er, f1_for_best_er))\n",
    "    print('best_conf_mat: {}'.format(best_conf_mat))\n",
    "    print('best_conf_mat_diag: {}'.format(np.diag(best_conf_mat)))\n",
    "\n",
    "print('\\n\\nMETRICS FOR ALL FOUR FOLDS: avg_er: {}, avg_f1: {}'.format(avg_er, avg_f1))\n",
    "print('MODEL AVERAGE OVER FOUR FOLDS: avg_er: {}, avg_f1: {}'.format(np.mean(avg_er), np.mean(avg_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd6d6cc-0fa4-4ee4-bd13-294db1d34592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12546fd7-e416-4e1f-a58a-c7011799bd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810386ae-8565-47b6-b0af-d1cd07e41dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407bb50-2d04-4de5-862c-e8b4d39a926d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c62334c-e9ba-4146-b077-0004e203be55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
